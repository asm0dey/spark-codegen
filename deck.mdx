import {
  CodeSurfer,
  CodeSurferColumns,
  Step,
} from "code-surfer";
import { dracula } from "@code-surfer/themes"
import "prismjs/components/prism-kotlin"
import "prismjs/components/prism-java"
import { SplitRight } from 'mdx-deck'
export const theme = dracula;

# Spark Magic:
## How High-level Pipelines Become Distributed Hardcore

Pasha Finkelshteyn, JetBrains


---

<SplitRight>

# Hi

# I'm Pasha

</SplitRight>

---

<CodeSurfer>

```kotlin 
data class Q<T>(val id: Int, val text: T)
object Main {
    @JvmStatic
    fun main(args: Array<String>) {

        val spark = SparkSession
            .builder()
            .master("local[2]")
            .appName("Simple Application").orCreate

        val triples = spark
            .toDS(listOf(Q(1, 1 to null), Q(2, 2 to "22"), Q(3, 3 to "333")))
            .map { (a, b) -> a + b.first to b.second?.length }
            .map { it to 1 }
            .map { (a, b) -> Triple(a.first, a.second, b) }


        val pairs = spark
            .toDS(listOf(2 to "hell", 4 to "moon", 6 to "berry"))

        triples
            .leftJoin(pairs, triples.col("first").multiply(2).eq(pairs.col("first")))
            .map { (triple, pair) -> Five(triple.first, triple.second, triple.third, pair?.first, pair?.second) }
            .groupByKey { it.a }
            .reduceGroupsK { v1, v2 -> v1.copy(a = v1.a + v2.a, b = v1.a + v2.a) }
            .map { it.second }
            .repartition(1)
            .withCached {
                write()
                    .also { it.csv("csvpath") }
                    .also { it.orc("orcpath") }
                showDS()
            }



        spark.stop()
    }

    data class Five<A, B, C, D, E>(val a: A, val b: B, val c: C, val d: D, val e: E)
}
```

```kotlin
fun main() {
    withSpark {
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
    }
}
```

```kotlin
    withSpark {
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
    }
```

```kotlin 1
    withSpark {
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
    }
```

```kotlin 1:2
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
```

```kotlin 3
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
```

```kotlin 4
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
```

```kotlin 5
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .show()
```

```sql
+-----+------+
|first|second|
+-----+------+
|   12|     m|
|   11|     l|
|   10|     k|
|    9|     j|
|    8|     i|
|    7|     h|
|    6|     g|
|    5|     f|
|    4|     e|
|    3|     d|
|    2|     c|
|    1|     b|
|    0|     a|
+-----+------+
```

```kotlin
        listOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sortedByDescending { it.first }
            .forEach {
               println("first: ${it.first}, second: ${it.second}") }
```

```kotlin 1:6
withSpark {
    dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
        "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
        .map { it.second - 1 to it.first }
        .sort { arrayOf(it.col("first").desc()) }
        .show()
}
```

```kotlin 1[10:30]
withSpark(master = "local[4]") {
    dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
        "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
        .map { it.second - 1 to it.first }
        .sort { arrayOf(it.col("first").desc()) }
        .show()
}
```

</CodeSurfer>

---

# Очень интересно и совсем непонятно!

---

<CodeSurfer>

```kotlin
dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
    "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
    .map { it.second - 1 to it.first }
    .sort { arrayOf(it.col("first").desc()) }
    .show()
```

```kotlin
dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
    "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
    .map { it.second - 1 to it.first }
    .sort { arrayOf(it.col("first").desc()) }
    .debugCodegen()
    .show()
```

</CodeSurfer>

---

<CodeSurfer>

```java
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator localtablescan_input_0;
/* 010 */   private int deserializetoobject_argValue_0;
/* 011 */   private java.lang.String[] deserializetoobject_mutableStateArray_0 = new java.lang.String[2];
/* 012 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 013 */   private java.lang.Integer[] deserializetoobject_mutableStateArray_1 = new java.lang.Integer[1];
/* 014 */   private kotlin.Pair[] mapelements_mutableStateArray_0 = new kotlin.Pair[1];
/* 015 */
/* 016 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 017 */     this.references = references;
/* 018 */   }
/* 019 */
/* 020 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 021 */     partitionIndex = index;
/* 022 */     this.inputs = inputs;
/* 023 */     localtablescan_input_0 = inputs[0];
/* 024 */
/* 025 */     deserializetoobject_mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 026 */     deserializetoobject_mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 027 */     deserializetoobject_mutableStateArray_2[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 028 */     deserializetoobject_mutableStateArray_2[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 029 */     deserializetoobject_mutableStateArray_2[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 030 */
/* 031 */   }
/* 032 */
/* 033 */   private void mapelements_doConsume_0(kotlin.Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws java.io.IOException {
/* 034 */     boolean mapelements_isNull_1 = true;
/* 035 */     kotlin.Pair mapelements_value_1 = null;
/* 036 */     if (!false) {
/* 037 */       mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;
/* 038 */
/* 039 */       mapelements_isNull_1 = false;
/* 040 */       if (!mapelements_isNull_1) {
/* 041 */         Object mapelements_funcResult_0 = null;
/* 042 */
/* 043 */         try {
/* 044 */           mapelements_funcResult_0 = ((org.apache.spark.api.java.function.MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);
/* 045 */         } catch (Exception e) {
/* 046 */           org.apache.spark.unsafe.Platform.throwException(e);
/* 047 */         }
/* 048 */
/* 049 */         if (mapelements_funcResult_0 != null) {
/* 050 */           mapelements_value_1 = (kotlin.Pair) mapelements_funcResult_0;
/* 051 */         } else {
/* 052 */           mapelements_isNull_1 = true;
/* 053 */         }
/* 054 */
/* 055 */       }
/* 056 */     }
/* 057 */
/* 058 */     serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);
/* 059 */
/* 060 */   }
/* 061 */
/* 062 */   private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0, UTF8String deserializetoobject_expr_0_0, int deserializetoobject_expr_1_0) throws java.io.IOException {
/* 063 */     boolean deserializetoobject_isNull_1 = true;
/* 064 */     java.lang.String deserializetoobject_value_1 = null;
/* 065 */     if (!false) {
/* 066 */       deserializetoobject_isNull_1 = false;
/* 067 */       if (!deserializetoobject_isNull_1) {
/* 068 */         Object deserializetoobject_funcResult_0 = null;
/* 069 */         deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();
/* 070 */         deserializetoobject_value_1 = (java.lang.String) deserializetoobject_funcResult_0;
/* 071 */
/* 072 */       }
/* 073 */     }
/* 074 */     deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;
/* 075 */
/* 076 */     deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;
/* 077 */
/* 078 */     java.lang.Integer deserializetoobject_value_3 = null;
/* 079 */     if (!false) {
/* 080 */       deserializetoobject_value_3 = java.lang.Integer.valueOf(deserializetoobject_argValue_0);
/* 081 */     }
/* 082 */     deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;
/* 083 */
/* 084 */     final kotlin.Pair deserializetoobject_value_0 = false ?
/* 085 */     null : new kotlin.Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);
/* 086 */
/* 087 */     mapelements_doConsume_0(deserializetoobject_value_0, false);
/* 088 */
/* 089 */   }
/* 090 */
/* 091 */   private void serializefromobject_doConsume_0(kotlin.Pair serializefromobject_expr_0_0, boolean serializefromobject_exprIsNull_0_0) throws java.io.IOException {
/* 092 */     if (serializefromobject_exprIsNull_0_0) {
/* 093 */       throw new NullPointerException(((java.lang.String) references[2] /* errMsg */));
/* 094 */     }
/* 095 */     boolean serializefromobject_isNull_1 = true;
/* 096 */     int serializefromobject_value_1 = -1;
/* 097 */     if (!false) {
/* 098 */       serializefromobject_isNull_1 = false;
/* 099 */       if (!serializefromobject_isNull_1) {
/* 100 */         Object serializefromobject_funcResult_0 = null;
/* 101 */         serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();
/* 102 */         serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;
/* 103 */
/* 104 */       }
/* 105 */     }
/* 106 */     if (serializefromobject_exprIsNull_0_0) {
/* 107 */       throw new NullPointerException(((java.lang.String) references[3] /* errMsg */));
/* 108 */     }
/* 109 */     boolean serializefromobject_isNull_5 = true;
/* 110 */     java.lang.String serializefromobject_value_5 = null;
/* 111 */     if (!false) {
/* 112 */       serializefromobject_isNull_5 = false;
/* 113 */       if (!serializefromobject_isNull_5) {
/* 114 */         Object serializefromobject_funcResult_1 = null;
/* 115 */         serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();
/* 116 */         serializefromobject_value_5 = (java.lang.String) serializefromobject_funcResult_1;
/* 117 */
/* 118 */       }
/* 119 */     }
/* 120 */     deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;
/* 121 */
/* 122 */     UTF8String serializefromobject_value_4 = null;
/* 123 */     if (!false) {
/* 124 */       serializefromobject_value_4 = org.apache.spark.unsafe.types.UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);
/* 125 */     }
/* 126 */     deserializetoobject_mutableStateArray_2[4].reset();
/* 127 */
/* 128 */     deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();
/* 129 */
/* 130 */     deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);
/* 131 */
/* 132 */     deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);
/* 133 */     append((deserializetoobject_mutableStateArray_2[4].getRow()));
/* 134 */
/* 135 */   }
/* 136 */
/* 137 */   protected void processNext() throws java.io.IOException {
/* 138 */     while ( localtablescan_input_0.hasNext()) {
/* 139 */       InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();
/* 140 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 141 */       UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);
/* 142 */       int localtablescan_value_1 = localtablescan_row_0.getInt(1);
/* 143 */
/* 144 */       deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);
/* 145 */       if (shouldStop()) return;
/* 146 */     }
/* 147 */   }
/* 148 */
/* 149 */ }
```

</CodeSurfer>

---

<CodeSurfer>


```java
import kotlin.Pair;
import org.apache.spark.api.java.function.MapFunction;
import org.apache.spark.sql.catalyst.InternalRow;
import org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;
import org.apache.spark.sql.execution.BufferedRowIterator;
import org.apache.spark.sql.execution.metric.SQLMetric;
import org.apache.spark.unsafe.Platform;
import org.apache.spark.unsafe.types.UTF8String;
import scala.collection.Iterator;

import java.io.IOException;

public Object generate(Object[]references){return new GeneratedIteratorForCodegenStage1(references);}

// codegenStageId=1
final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {
    private Object[] references;
    private Iterator[] inputs;
    private Iterator localtablescan_input_0;
    private int deserializetoobject_argValue_0;
    private String[] deserializetoobject_mutableStateArray_0 = new String[2];
    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];
    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];
    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];

    public GeneratedIteratorForCodegenStage1(Object[] references) {
        this.references = references;
    }

    public void init(int index, Iterator[] inputs) {
        partitionIndex = index;
        this.inputs = inputs;
        localtablescan_input_0 = inputs[0];

        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);

    }

    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {
        boolean mapelements_isNull_1 = true;
        Pair mapelements_value_1 = null;
        if (!false) {
            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;

            mapelements_isNull_1 = false;
            if (!mapelements_isNull_1) {
                Object mapelements_funcResult_0 = null;

                try {
                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);
                } catch (Exception e) {
                    Platform.throwException(e);
                }

                if (mapelements_funcResult_0 != null) {
                    mapelements_value_1 = (Pair) mapelements_funcResult_0;
                } else {
                    mapelements_isNull_1 = true;
                }

            }
        }

        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);

    }

    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,
                                                 UTF8String deserializetoobject_expr_0_0,
                                                 int deserializetoobject_expr_1_0) throws IOException {
        boolean deserializetoobject_isNull_1 = true;
        String deserializetoobject_value_1 = null;
        if (!false) {
            deserializetoobject_isNull_1 = false;
            if (!deserializetoobject_isNull_1) {
                Object deserializetoobject_funcResult_0 = null;
                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();
                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;

            }
        }
        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;

        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;

        Integer deserializetoobject_value_3 = null;
        if (!false) {
            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);
        }
        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;

        final Pair deserializetoobject_value_0 = false ?
                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);

        mapelements_doConsume_0(deserializetoobject_value_0, false);

    }

    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,
                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {
        if (serializefromobject_exprIsNull_0_0) {
            throw new NullPointerException(((String) references[2] /* errMsg */));
        }
        boolean serializefromobject_isNull_1 = true;
        int serializefromobject_value_1 = -1;
        if (!false) {
            serializefromobject_isNull_1 = false;
            if (!serializefromobject_isNull_1) {
                Object serializefromobject_funcResult_0 = null;
                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();
                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;

            }
        }
        if (serializefromobject_exprIsNull_0_0) {
            throw new NullPointerException(((String) references[3] /* errMsg */));
        }
        boolean serializefromobject_isNull_5 = true;
        String serializefromobject_value_5 = null;
        if (!false) {
            serializefromobject_isNull_5 = false;
            if (!serializefromobject_isNull_5) {
                Object serializefromobject_funcResult_1 = null;
                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();
                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;

            }
        }
        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;

        UTF8String serializefromobject_value_4 = null;
        if (!false) {
            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);
        }
        deserializetoobject_mutableStateArray_2[4].reset();

        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();

        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);

        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);
        append((deserializetoobject_mutableStateArray_2[4].getRow()));

    }

    protected void processNext() throws IOException {
        while (localtablescan_input_0.hasNext()) {
            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();
            ((SQLMetric) references[0] /* numOutputRows */).add(1);
            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);
            int localtablescan_value_1 = localtablescan_row_0.getInt(1);

            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);
            if (shouldStop()) return;
        }
    }

}
```

```java 1
public Object generate(Object[]references){return new GeneratedIteratorForCodegenStage1(references);}

// codegenStageId=1
final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {
    private Object[] references;
    private Iterator[] inputs;
    private Iterator localtablescan_input_0;
    private int deserializetoobject_argValue_0;
    private String[] deserializetoobject_mutableStateArray_0 = new String[2];
    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];
    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];
    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];

    public GeneratedIteratorForCodegenStage1(Object[] references) {
        this.references = references;
    }

    public void init(int index, Iterator[] inputs) {
        partitionIndex = index;
        this.inputs = inputs;
        localtablescan_input_0 = inputs[0];

        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);
        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);

    }

    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {
        boolean mapelements_isNull_1 = true;
        Pair mapelements_value_1 = null;
        if (!false) {
            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;

            mapelements_isNull_1 = false;
            if (!mapelements_isNull_1) {
                Object mapelements_funcResult_0 = null;

                try {
                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);
                } catch (Exception e) {
                    Platform.throwException(e);
                }

                if (mapelements_funcResult_0 != null) {
                    mapelements_value_1 = (Pair) mapelements_funcResult_0;
                } else {
                    mapelements_isNull_1 = true;
                }

            }
        }

        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);

    }

    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,
                                                 UTF8String deserializetoobject_expr_0_0,
                                                 int deserializetoobject_expr_1_0) throws IOException {
        boolean deserializetoobject_isNull_1 = true;
        String deserializetoobject_value_1 = null;
        if (!false) {
            deserializetoobject_isNull_1 = false;
            if (!deserializetoobject_isNull_1) {
                Object deserializetoobject_funcResult_0 = null;
                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();
                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;

            }
        }
        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;

        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;

        Integer deserializetoobject_value_3 = null;
        if (!false) {
            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);
        }
        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;

        final Pair deserializetoobject_value_0 = false ?
                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);

        mapelements_doConsume_0(deserializetoobject_value_0, false);

    }

    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,
                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {
        if (serializefromobject_exprIsNull_0_0) {
            throw new NullPointerException(((String) references[2] /* errMsg */));
        }
        boolean serializefromobject_isNull_1 = true;
        int serializefromobject_value_1 = -1;
        if (!false) {
            serializefromobject_isNull_1 = false;
            if (!serializefromobject_isNull_1) {
                Object serializefromobject_funcResult_0 = null;
                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();
                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;

            }
        }
        if (serializefromobject_exprIsNull_0_0) {
            throw new NullPointerException(((String) references[3] /* errMsg */));
        }
        boolean serializefromobject_isNull_5 = true;
        String serializefromobject_value_5 = null;
        if (!false) {
            serializefromobject_isNull_5 = false;
            if (!serializefromobject_isNull_5) {
                Object serializefromobject_funcResult_1 = null;
                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();
                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;

            }
        }
        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;

        UTF8String serializefromobject_value_4 = null;
        if (!false) {
            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);
        }
        deserializetoobject_mutableStateArray_2[4].reset();

        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();

        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);

        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);
        append((deserializetoobject_mutableStateArray_2[4].getRow()));

    }

    protected void processNext() throws IOException {
        while (localtablescan_input_0.hasNext()) {
            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();
            ((SQLMetric) references[0] /* numOutputRows */).add(1);
            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);
            int localtablescan_value_1 = localtablescan_row_0.getInt(1);

            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);
            if (shouldStop()) return;
        }
    }

}
```

```java 135:145 file=./snippets/1.java
```

```java 57:86 file=./snippets/1.java
```

```java 28:53 file=./snippets/1.java
```

```java 88:132 file=./snippets/1.java
```

```java 124:131 file=./snippets/1.java
```

</CodeSurfer>

---

# Всё ещё непонятно

- Код генерируется
- Цикл бегает
- Что-то кудато добавляется

---

<CodeSurfer>

```kotlin
    withSpark(
        master = "local[4]",
    ) {
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .debugCodegen()
            .show()
    }
```

```kotlin
    withSpark(
        master = "local[4]",
        props = mapOf("spark.sql.codegen.comments" to true)
    ) {
        dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
            "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
            .map { it.second - 1 to it.first }
            .sort { arrayOf(it.col("first").desc()) }
            .debugCodegen()
            .show()
    }
```

```java file=./2.java
```

```java 150:156 file=./2.java
```

```java 156 file=./2.java
```

```java 155 file=./2.java
```

```java 153:154 file=./2.java
```

```java 150:152 file=./2.java
```

```java 160:162 file=./2.java
```

```java 163:164 file=./2.java
```

```java 166 file=./2.java
```

```java 62:67 file=./2.java
```

```java 68:80 file=./2.java
```

```java 82:89 file=./2.java
```

```java 91:92 file=./2.java
```

```java 94 file=./2.java
```

```java 29:32 file=./2.java
```

```java 28[41:67],36 file=./2.java
```

```java 36,43,44 file=./2.java
```

```java 50,58 file=./2.java
```

```java 100 file=./2.java
```

```java 98[49:83],101,111,112 file=./2.java
```

```java 116,117,127,128 file=./2.java
```

```java 134:137 file=./2.java
```

```java 136,144 file=./2.java
```

```java
  public static void copyMemory(
    Object src, long srcOffset, Object dst, long dstOffset, long length) {
    // Check if dstOffset is before or after srcOffset to determine if we should copy
    // forward or backwards. This is necessary in case src and dst overlap.
    if (dstOffset < srcOffset) {
      while (length > 0) {
        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);
        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);
        length -= size;
        srcOffset += size;
        dstOffset += size;
      }
    } else {
      srcOffset += length;
      dstOffset += length;
      while (length > 0) {
        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);
        srcOffset -= size;
        dstOffset -= size;
        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);
        length -= size;
      }

    }
  }
```

```java 8 title="sun.misc.Unsafe O_o"
  public static void copyMemory(
    Object src, long srcOffset, Object dst, long dstOffset, long length) {
    // Check if dstOffset is before or after srcOffset to determine if we should copy
    // forward or backwards. This is necessary in case src and dst overlap.
    if (dstOffset < srcOffset) {
      while (length > 0) {
        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);
        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);
        length -= size;
        srcOffset += size;
        dstOffset += size;
      }
    } else {
      srcOffset += length;
      dstOffset += length;
      while (length > 0) {
        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);
        srcOffset -= size;
        dstOffset -= size;
        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);
        length -= size;
      }

    }
  }
```

</CodeSurfer>

---

# Почему мы закончили на `_UNSAFE`?

Потому что впереди ещё сортировка

---

# Почему мы закончили на `_UNSAFE`?

Потому что впереди ещё сортировка

Но я вам её не покажу

Пора понять как мы к этим сгенерированным исходникам приходим

---

<CodeSurfer>

```kotlin
dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
    "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
    .map { it.second - 1 to it.first }
    .sort { arrayOf(it.col("first").desc()) }
    .debugCodegen()
    .show()
```

```kotlin 1[1:4]
dsOf("a" to 1, "b" to 2, "c" to 3, "d" to 4, "e" to 5, "f" to 6,
    "g" to 7, "h" to 8, "i" to 9, "j" to 10, "k" to 11, "l" to 12, "m" to 13)
    .map { it.second - 1 to it.first }
    .sort { arrayOf(it.col("first").desc()) }
    .debugCodegen()
    .show()
```

```kotlin
inline fun <reified T> SparkSession.dsOf(vararg t: T): Dataset<T> =
    createDataset(listOf(*t), encoder<T>())
```

```kotlin 2[31:42]
inline fun <reified T> SparkSession.dsOf(vararg t: T): Dataset<T> =
    createDataset(listOf(*t), encoder<T>())
```

```kotlin
@OptIn(ExperimentalStdlibApi::class)
inline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)
```

```kotlin 1,2[64:74] subtitle="Аналог ParametryzedTypeReferense в compile-time"
@OptIn(ExperimentalStdlibApi::class)
inline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)
```

```kotlin 2[48:85] subtitle="encoder → generateEncoder"
@OptIn(ExperimentalStdlibApi::class)
inline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)
```

```kotlin 4[53:72]
fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {
    @Suppress("UNCHECKED_CAST")
    return when {
        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)
        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)
    } as Encoder<T>
}
```

```kotlin title="Мемоизация на коленке"
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin title="Мемоизация на коленке" subtitle="Мне сказали что это сложно, так что давайте разбираться"
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 1:5
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 1[16:26] subtitle="Java PECS → Kotlin PICO"
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 1[48:55]
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 1[29:43]
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 2
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 3[18:29]
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 3,4
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 4[16:36]
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 1[29:43],3[25:28],4[28:35]
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 7
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 9 subtitle="Поле функционального типа (T) -> R"
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 9[44:52] subtitle="schema?"
class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {
    private val values = ConcurrentHashMap<T, R>()
    override fun invoke(x: T) =
        values.getOrPut(x, { f(x) })
}

private fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)

private val memoizedSchema = { x: KType -> schema(x) }.memoize()
```

```kotlin 2 file=./schema.kt
```

```kotlin 2[25:57] file=./schema.kt subtitle="Pair<A, B> → Pair<String, Int>"
```

```kotlin 2[61:68] file=./schema.kt subtitle="Pair<A, B> → Pair<String, Int>"
```

```kotlin 3:6 file=./schema.kt
```

```kotlin
private val knownDataTypes = mapOf(
    Byte::class to DataTypes.ByteType,
    Short::class to DataTypes.ShortType,
    Int::class to DataTypes.IntegerType,
    Long::class to DataTypes.LongType,
    Boolean::class to DataTypes.BooleanType,
    Float::class to DataTypes.FloatType,
    Double::class to DataTypes.DoubleType,
    String::class to DataTypes.StringType,
    LocalDate::class to `DateType$`.`MODULE$`,
    Date::class to `DateType$`.`MODULE$`,
    Timestamp::class to `TimestampType$`.`MODULE$`,
    Instant::class to `TimestampType$`.`MODULE$`
)
```


```kotlin 7 file=./schema.kt
```

```kotlin 9 file=./schema.kt
```

```kotlin 11[38:67] file=./schema.kt subtitle="List<Pair<KTypeParameter, KTypeProjection>>"
```

```kotlin 12 file=./schema.kt subtitle="\"A\" to String"
```

```kotlin 2[25:57],11:13 file=./schema.kt subtitle="Merge types with previous iteration"
```

```kotlin 15:17 file=./schema.kt
```

```kotlin 18:36 file=./schema.kt
```

```kotlin 19[17:25] file=./schema.kt
```

```kotlin 19[29:53],20:29 file=./schema.kt
```

```kotlin 30[15:63] file=./schema.kt
```

```kotlin 31:35 file=./schema.kt
```

```kotlin 37:49 file=./schema.kt
```

```kotlin 50:74 file=./schema.kt
```

```kotlin 52:53 file=./schema.kt
```

```kotlin 54:55 file=./schema.kt
```

```kotlin 57 file=./schema.kt
```

```kotlin 58:64 file=./schema.kt
```

```kotlin 66:69 file=./schema.kt
```

```kotlin 65:69 file=./schema.kt
```

```kotlin 73 file=./schema.kt
```

```kotlin 75:94 file=./schema.kt
```

```scala file=./helpers.scala title="Стройная система костылей"
```

```kotlin 2[61:68] file=./schema.kt
```

```kotlin
fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {
    @Suppress("UNCHECKED_CAST")
    return when {
        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)
        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)
    } as Encoder<T>
}
```

```kotlin 4[34:78]
fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {
    @Suppress("UNCHECKED_CAST")
    return when {
        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)
        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)
    } as Encoder<T>
}
```

```kotlin
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 2
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 3,4
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 5,6
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 7:10
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 11
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```kotlin 2[12:28]
private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {
    return ExpressionEncoder(
        if (schema is DataTypeWithClass) 
            KotlinReflection.serializerFor(kClass.java, schema)
        else
            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),
        if (schema is DataTypeWithClass) 
            KotlinReflection.deserializerFor(kClass.java, schema) 
        else 
            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),
        ClassTag.apply(kClass.java)
    )
}
```

```scala file=./serializerFor.scala
```

```scala 1 file=./serializerFor.scala
```

```scala 1[68:77] file=./serializerFor.scala subtitle="It's called expression, but really it may be the giant code block"
```

```scala title="The most important method"
  /**
   * Returns an [[ExprCode]], that contains the Java source code to generate the result of
   * evaluating the expression on an input row.
   *
   * @param ctx a [[CodegenContext]]
   * @return [[ExprCode]]
   */
  def genCode(ctx: CodegenContext): ExprCode = {
      // ommited
  }
```

```scala 2 file=./serializerFor.scala subtitle="Obtain Scala type from Java class"
```

```scala 3 file=./serializerFor.scala subtitle="Obtain class name"
```

```scala 4 file=./serializerFor.scala subtitle="Walked typed path is used for exceptions to determine what's going wrong"
```

```scala 6 file=./serializerFor.scala subtitle="Calling recursive serializer creation"
```

```scala 6[53:75] file=./serializerFor.scala subtitle="Supplying our predefined schema"
```

```scala file=./serializerFor2.scala subtitle="316-line-height"
```

```scala 1:7 file=./serializerFor2.scala
```

```scala 58:59 file=./serializerFor2.scala subtitle="simple input object"
```

```scala 111:112 file=./serializerFor2.scala subtitle="string"
```

```scala
def createSerializerForString(inputObject: Expression): Expression = {
    StaticInvoke(
        classOf[UTF8String],
        StringType,
        "fromString",
        inputObject :: Nil,
        returnNullable = false)
}
```

```scala 113:118 file=./serializerFor2.scala subtitle="string"
```

</CodeSurfer>

---

# The End