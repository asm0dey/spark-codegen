{"componentChunkName":"component---gatsby-theme-mdx-deck-src-templates-deck-js","path":"/","matchPath":"/*","result":{"data":{"deck":{"id":"5c475aae-6962-52cb-b39f-edcd89e96b3f","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar theme = dracula;\nvar _frontmatter = {};\nvar layoutProps = {\n  theme: theme,\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Spark Magic:\"), mdx(\"h2\", null, \"How High-level Pipelines Become Distributed Hardcore\"), mdx(\"p\", null, \"Pasha Finkelshteyn, JetBrains\"), mdx(\"hr\", null), mdx(SplitRight, {\n    mdxType: \"SplitRight\"\n  }, mdx(\"h1\", null, \"Hi\"), mdx(\"h1\", null, \"I'm Pasha\")), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"data class Q<T>(val id: Int, val text: T)\\nobject Main {\\n    @JvmStatic\\n    fun main(args: Array<String>) {\\n\\n        val spark = SparkSession\\n            .builder()\\n            .master(\\\"local[2]\\\")\\n            .appName(\\\"Simple Application\\\").orCreate\\n\\n        val triples = spark\\n            .toDS(listOf(Q(1, 1 to null), Q(2, 2 to \\\"22\\\"), Q(3, 3 to \\\"333\\\")))\\n            .map { (a, b) -> a + b.first to b.second?.length }\\n            .map { it to 1 }\\n            .map { (a, b) -> Triple(a.first, a.second, b) }\\n\\n\\n        val pairs = spark\\n            .toDS(listOf(2 to \\\"hell\\\", 4 to \\\"moon\\\", 6 to \\\"berry\\\"))\\n\\n        triples\\n            .leftJoin(pairs, triples.col(\\\"first\\\").multiply(2).eq(pairs.col(\\\"first\\\")))\\n            .map { (triple, pair) -> Five(triple.first, triple.second, triple.third, pair?.first, pair?.second) }\\n            .groupByKey { it.a }\\n            .reduceGroupsK { v1, v2 -> v1.copy(a = v1.a + v2.a, b = v1.a + v2.a) }\\n            .map { it.second }\\n            .repartition(1)\\n            .withCached {\\n                write()\\n                    .also { it.csv(\\\"csvpath\\\") }\\n                    .also { it.orc(\\\"orcpath\\\") }\\n                showDS()\\n            }\\n\\n\\n\\n        spark.stop()\\n    }\\n\\n    data class Five<A, B, C, D, E>(val a: A, val b: B, val c: C, val d: D, val e: E)\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"fun main() {\\n    withSpark {\\n        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"    withSpark {\\n        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n    }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"1\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1\"\n  }, \"    withSpark {\\n        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n    }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1:2\",\n    \"1:2\": true\n  }, \"        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"3\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"3\"\n  }, \"        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"4\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"4\"\n  }, \"        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"5\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"5\"\n  }, \"        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sql\"\n  }, \"+-----+------+\\n|first|second|\\n+-----+------+\\n|   12|     m|\\n|   11|     l|\\n|   10|     k|\\n|    9|     j|\\n|    8|     i|\\n|    7|     h|\\n|    6|     g|\\n|    5|     f|\\n|    4|     e|\\n|    3|     d|\\n|    2|     c|\\n|    1|     b|\\n|    0|     a|\\n+-----+------+\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"        listOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sortedByDescending { it.first }\\n            .forEach {\\n               println(\\\"first: ${it.first}, second: ${it.second}\\\") }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1:6\",\n    \"1:6\": true\n  }, \"withSpark {\\n    dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n        \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n        .map { it.second - 1 to it.first }\\n        .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n        .show()\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[10:30]\",\n    \"1[10:30]\": true\n  }, \"withSpark(master = \\\"local[4]\\\") {\\n    dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n        \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n        .map { it.second - 1 to it.first }\\n        .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n        .show()\\n}\\n\"))), mdx(\"hr\", null), mdx(\"h1\", null, \"\\u041E\\u0447\\u0435\\u043D\\u044C \\u0438\\u043D\\u0442\\u0435\\u0440\\u0435\\u0441\\u043D\\u043E \\u0438 \\u0441\\u043E\\u0432\\u0441\\u0435\\u043C \\u043D\\u0435\\u043F\\u043E\\u043D\\u044F\\u0442\\u043D\\u043E!\"), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n    \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n    .map { it.second - 1 to it.first }\\n    .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n    .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n    \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n    .map { it.second - 1 to it.first }\\n    .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n    .debugCodegen()\\n    .show()\\n\"))), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\"\n  }, \"/* 001 */ public Object generate(Object[] references) {\\n/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\\n/* 003 */ }\\n/* 004 */\\n/* 005 */ // codegenStageId=1\\n/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n/* 007 */   private Object[] references;\\n/* 008 */   private scala.collection.Iterator[] inputs;\\n/* 009 */   private scala.collection.Iterator localtablescan_input_0;\\n/* 010 */   private int deserializetoobject_argValue_0;\\n/* 011 */   private java.lang.String[] deserializetoobject_mutableStateArray_0 = new java.lang.String[2];\\n/* 012 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];\\n/* 013 */   private java.lang.Integer[] deserializetoobject_mutableStateArray_1 = new java.lang.Integer[1];\\n/* 014 */   private kotlin.Pair[] mapelements_mutableStateArray_0 = new kotlin.Pair[1];\\n/* 015 */\\n/* 016 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\\n/* 017 */     this.references = references;\\n/* 018 */   }\\n/* 019 */\\n/* 020 */   public void init(int index, scala.collection.Iterator[] inputs) {\\n/* 021 */     partitionIndex = index;\\n/* 022 */     this.inputs = inputs;\\n/* 023 */     localtablescan_input_0 = inputs[0];\\n/* 024 */\\n/* 025 */     deserializetoobject_mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\\n/* 026 */     deserializetoobject_mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\\n/* 027 */     deserializetoobject_mutableStateArray_2[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\\n/* 028 */     deserializetoobject_mutableStateArray_2[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\\n/* 029 */     deserializetoobject_mutableStateArray_2[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);\\n/* 030 */\\n/* 031 */   }\\n/* 032 */\\n/* 033 */   private void mapelements_doConsume_0(kotlin.Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws java.io.IOException {\\n/* 034 */     boolean mapelements_isNull_1 = true;\\n/* 035 */     kotlin.Pair mapelements_value_1 = null;\\n/* 036 */     if (!false) {\\n/* 037 */       mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n/* 038 */\\n/* 039 */       mapelements_isNull_1 = false;\\n/* 040 */       if (!mapelements_isNull_1) {\\n/* 041 */         Object mapelements_funcResult_0 = null;\\n/* 042 */\\n/* 043 */         try {\\n/* 044 */           mapelements_funcResult_0 = ((org.apache.spark.api.java.function.MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n/* 045 */         } catch (Exception e) {\\n/* 046 */           org.apache.spark.unsafe.Platform.throwException(e);\\n/* 047 */         }\\n/* 048 */\\n/* 049 */         if (mapelements_funcResult_0 != null) {\\n/* 050 */           mapelements_value_1 = (kotlin.Pair) mapelements_funcResult_0;\\n/* 051 */         } else {\\n/* 052 */           mapelements_isNull_1 = true;\\n/* 053 */         }\\n/* 054 */\\n/* 055 */       }\\n/* 056 */     }\\n/* 057 */\\n/* 058 */     serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n/* 059 */\\n/* 060 */   }\\n/* 061 */\\n/* 062 */   private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0, UTF8String deserializetoobject_expr_0_0, int deserializetoobject_expr_1_0) throws java.io.IOException {\\n/* 063 */     boolean deserializetoobject_isNull_1 = true;\\n/* 064 */     java.lang.String deserializetoobject_value_1 = null;\\n/* 065 */     if (!false) {\\n/* 066 */       deserializetoobject_isNull_1 = false;\\n/* 067 */       if (!deserializetoobject_isNull_1) {\\n/* 068 */         Object deserializetoobject_funcResult_0 = null;\\n/* 069 */         deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n/* 070 */         deserializetoobject_value_1 = (java.lang.String) deserializetoobject_funcResult_0;\\n/* 071 */\\n/* 072 */       }\\n/* 073 */     }\\n/* 074 */     deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n/* 075 */\\n/* 076 */     deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n/* 077 */\\n/* 078 */     java.lang.Integer deserializetoobject_value_3 = null;\\n/* 079 */     if (!false) {\\n/* 080 */       deserializetoobject_value_3 = java.lang.Integer.valueOf(deserializetoobject_argValue_0);\\n/* 081 */     }\\n/* 082 */     deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n/* 083 */\\n/* 084 */     final kotlin.Pair deserializetoobject_value_0 = false ?\\n/* 085 */     null : new kotlin.Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n/* 086 */\\n/* 087 */     mapelements_doConsume_0(deserializetoobject_value_0, false);\\n/* 088 */\\n/* 089 */   }\\n/* 090 */\\n/* 091 */   private void serializefromobject_doConsume_0(kotlin.Pair serializefromobject_expr_0_0, boolean serializefromobject_exprIsNull_0_0) throws java.io.IOException {\\n/* 092 */     if (serializefromobject_exprIsNull_0_0) {\\n/* 093 */       throw new NullPointerException(((java.lang.String) references[2] /* errMsg */));\\n/* 094 */     }\\n/* 095 */     boolean serializefromobject_isNull_1 = true;\\n/* 096 */     int serializefromobject_value_1 = -1;\\n/* 097 */     if (!false) {\\n/* 098 */       serializefromobject_isNull_1 = false;\\n/* 099 */       if (!serializefromobject_isNull_1) {\\n/* 100 */         Object serializefromobject_funcResult_0 = null;\\n/* 101 */         serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n/* 102 */         serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n/* 103 */\\n/* 104 */       }\\n/* 105 */     }\\n/* 106 */     if (serializefromobject_exprIsNull_0_0) {\\n/* 107 */       throw new NullPointerException(((java.lang.String) references[3] /* errMsg */));\\n/* 108 */     }\\n/* 109 */     boolean serializefromobject_isNull_5 = true;\\n/* 110 */     java.lang.String serializefromobject_value_5 = null;\\n/* 111 */     if (!false) {\\n/* 112 */       serializefromobject_isNull_5 = false;\\n/* 113 */       if (!serializefromobject_isNull_5) {\\n/* 114 */         Object serializefromobject_funcResult_1 = null;\\n/* 115 */         serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n/* 116 */         serializefromobject_value_5 = (java.lang.String) serializefromobject_funcResult_1;\\n/* 117 */\\n/* 118 */       }\\n/* 119 */     }\\n/* 120 */     deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n/* 121 */\\n/* 122 */     UTF8String serializefromobject_value_4 = null;\\n/* 123 */     if (!false) {\\n/* 124 */       serializefromobject_value_4 = org.apache.spark.unsafe.types.UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n/* 125 */     }\\n/* 126 */     deserializetoobject_mutableStateArray_2[4].reset();\\n/* 127 */\\n/* 128 */     deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n/* 129 */\\n/* 130 */     deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n/* 131 */\\n/* 132 */     deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n/* 133 */     append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n/* 134 */\\n/* 135 */   }\\n/* 136 */\\n/* 137 */   protected void processNext() throws java.io.IOException {\\n/* 138 */     while ( localtablescan_input_0.hasNext()) {\\n/* 139 */       InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n/* 140 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n/* 141 */       UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n/* 142 */       int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n/* 143 */\\n/* 144 */       deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n/* 145 */       if (shouldStop()) return;\\n/* 146 */     }\\n/* 147 */   }\\n/* 148 */\\n/* 149 */ }\\n\"))), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\"\n  }, \"import kotlin.Pair;\\nimport org.apache.spark.api.java.function.MapFunction;\\nimport org.apache.spark.sql.catalyst.InternalRow;\\nimport org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;\\nimport org.apache.spark.sql.execution.BufferedRowIterator;\\nimport org.apache.spark.sql.execution.metric.SQLMetric;\\nimport org.apache.spark.unsafe.Platform;\\nimport org.apache.spark.unsafe.types.UTF8String;\\nimport scala.collection.Iterator;\\n\\nimport java.io.IOException;\\n\\npublic Object generate(Object[]references){return new GeneratedIteratorForCodegenStage1(references);}\\n\\n// codegenStageId=1\\nfinal class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"1\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"1\"\n  }, \"public Object generate(Object[]references){return new GeneratedIteratorForCodegenStage1(references);}\\n\\n// codegenStageId=1\\nfinal class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"135:145 file=./snippets/1.java\",\n    \"135:145\": true,\n    \"file\": \"./snippets/1.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"57:86 file=./snippets/1.java\",\n    \"57:86\": true,\n    \"file\": \"./snippets/1.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"28:53 file=./snippets/1.java\",\n    \"28:53\": true,\n    \"file\": \"./snippets/1.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"88:132 file=./snippets/1.java\",\n    \"88:132\": true,\n    \"file\": \"./snippets/1.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"124:131 file=./snippets/1.java\",\n    \"124:131\": true,\n    \"file\": \"./snippets/1.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends BufferedRowIterator {\\n    private Object[] references;\\n    private Iterator[] inputs;\\n    private Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */).call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ?\\n                null : new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((SQLMetric) references[0] /* numOutputRows */).add(1);\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\"))), mdx(\"hr\", null), mdx(\"h1\", null, \"\\u0412\\u0441\\u0451 \\u0435\\u0449\\u0451 \\u043D\\u0435\\u043F\\u043E\\u043D\\u044F\\u0442\\u043D\\u043E\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u041A\\u043E\\u0434 \\u0433\\u0435\\u043D\\u0435\\u0440\\u0438\\u0440\\u0443\\u0435\\u0442\\u0441\\u044F\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u0426\\u0438\\u043A\\u043B \\u0431\\u0435\\u0433\\u0430\\u0435\\u0442\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u0427\\u0442\\u043E-\\u0442\\u043E \\u043A\\u0443\\u0434\\u0430\\u0442\\u043E \\u0434\\u043E\\u0431\\u0430\\u0432\\u043B\\u044F\\u0435\\u0442\\u0441\\u044F\")), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"    withSpark(\\n        master = \\\"local[4]\\\",\\n    ) {\\n        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .debugCodegen()\\n            .show()\\n    }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"    withSpark(\\n        master = \\\"local[4]\\\",\\n        props = mapOf(\\\"spark.sql.codegen.comments\\\" to true)\\n    ) {\\n        dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n            \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n            .map { it.second - 1 to it.first }\\n            .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n            .debugCodegen()\\n            .show()\\n    }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"150:156 file=./2.java\",\n    \"150:156\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"156\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"156 file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"155\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"155 file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"153:154 file=./2.java\",\n    \"153:154\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"150:152 file=./2.java\",\n    \"150:152\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"160:162 file=./2.java\",\n    \"160:162\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"163:164 file=./2.java\",\n    \"163:164\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"166\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"166 file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"62:67 file=./2.java\",\n    \"62:67\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"68:80 file=./2.java\",\n    \"68:80\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"82:89 file=./2.java\",\n    \"82:89\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"91:92 file=./2.java\",\n    \"91:92\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"94\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"94 file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"29:32 file=./2.java\",\n    \"29:32\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"28[41:67],36 file=./2.java\",\n    \"28[41:67],36\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"36,43,44 file=./2.java\",\n    \"36,43,44\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"50,58 file=./2.java\",\n    \"50,58\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"100\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"100 file=./2.java\",\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"98[49:83],101,111,112 file=./2.java\",\n    \"98[49:83],101,111,112\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"116,117,127,128 file=./2.java\",\n    \"116,117,127,128\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"134:137 file=./2.java\",\n    \"134:137\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\",\n    \"metastring\": \"136,144 file=./2.java\",\n    \"136,144\": true,\n    \"file\": \"./2.java\"\n  }, \"final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\\n    private Object[] references;\\n    private scala.collection.Iterator[] inputs;\\n    private scala.collection.Iterator localtablescan_input_0;\\n    private int deserializetoobject_argValue_0;\\n    private String[] deserializetoobject_mutableStateArray_0 = new String[2];\\n    private UnsafeRowWriter[] deserializetoobject_mutableStateArray_2 = new UnsafeRowWriter[5];\\n    private Integer[] deserializetoobject_mutableStateArray_1 = new Integer[1];\\n    private Pair[] mapelements_mutableStateArray_0 = new Pair[1];\\n\\n    public GeneratedIteratorForCodegenStage1(Object[] references) {\\n        this.references = references;\\n    }\\n\\n    public void init(int index, scala.collection.Iterator[] inputs) {\\n        partitionIndex = index;\\n        this.inputs = inputs;\\n        localtablescan_input_0 = inputs[0];\\n\\n        deserializetoobject_mutableStateArray_2[0] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[1] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[2] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[3] = new UnsafeRowWriter(1, 32);\\n        deserializetoobject_mutableStateArray_2[4] = new UnsafeRowWriter(2, 32);\\n\\n    }\\n\\n    private void mapelements_doConsume_0(Pair mapelements_expr_0_0, boolean mapelements_exprIsNull_0_0) throws IOException {\\n        // CONSUME: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //          assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799.call\\n        boolean mapelements_isNull_1 = true;\\n        Pair mapelements_value_1 = null;\\n        if (!false) {\\n            mapelements_mutableStateArray_0[0] = mapelements_expr_0_0;\\n\\n            mapelements_isNull_1 = false;\\n            if (!mapelements_isNull_1) {\\n                Object mapelements_funcResult_0 = null;\\n\\n                try {\\n                    mapelements_funcResult_0 = ((MapFunction) references[1] /* literal */)\\n                            .call(mapelements_mutableStateArray_0[0]);\\n                } catch (Exception e) {\\n                    org.apache.spark.unsafe.Platform.throwException(e);\\n                }\\n\\n                if (mapelements_funcResult_0 != null) {\\n                    mapelements_value_1 = (Pair) mapelements_funcResult_0;\\n                } else {\\n                    mapelements_isNull_1 = true;\\n                }\\n\\n            }\\n        }\\n\\n        serializefromobject_doConsume_0(mapelements_value_1, mapelements_isNull_1);\\n\\n    }\\n\\n    private void deserializetoobject_doConsume_0(InternalRow localtablescan_row_0,\\n                                                 UTF8String deserializetoobject_expr_0_0,\\n                                                 int deserializetoobject_expr_1_0) throws IOException {\\n        // CONSUME: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //          obj#24: kotlin.Pair\\n        // newInstance(class kotlin.Pair)\\n        // input[0, string, false].toString\\n        boolean deserializetoobject_isNull_1 = true;\\n        String deserializetoobject_value_1 = null;\\n        if (!false) {\\n            deserializetoobject_isNull_1 = false;\\n            if (!deserializetoobject_isNull_1) {\\n                Object deserializetoobject_funcResult_0 = null;\\n                deserializetoobject_funcResult_0 = deserializetoobject_expr_0_0.toString();\\n                deserializetoobject_value_1 = (String) deserializetoobject_funcResult_0;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[0] = deserializetoobject_value_1;\\n\\n        // staticinvoke(class java.lang.Integer, ObjectType(class java.lang.Integer), valueOf, input[1, int, false], true, false)\\n        deserializetoobject_argValue_0 = deserializetoobject_expr_1_0;\\n\\n        Integer deserializetoobject_value_3 = null;\\n        if (!false) {\\n            deserializetoobject_value_3 = Integer.valueOf(deserializetoobject_argValue_0);\\n        }\\n        deserializetoobject_mutableStateArray_1[0] = deserializetoobject_value_3;\\n\\n        final Pair deserializetoobject_value_0 = false ? null :\\n                new Pair(deserializetoobject_mutableStateArray_0[0], deserializetoobject_mutableStateArray_1[0]);\\n\\n        mapelements_doConsume_0(deserializetoobject_value_0, false);\\n\\n    }\\n\\n    private void serializefromobject_doConsume_0(Pair serializefromobject_expr_0_0,\\n                                                 boolean serializefromobject_exprIsNull_0_0) throws IOException {\\n        // CONSUME: WholeStageCodegen (1)\\n        // assertnotnull(input[0, kotlin.Pair, true]).getFirst\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[2] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_1 = true;\\n        int serializefromobject_value_1 = -1;\\n        if (!false) {\\n            serializefromobject_isNull_1 = false;\\n            if (!serializefromobject_isNull_1) {\\n                Object serializefromobject_funcResult_0 = null;\\n                serializefromobject_funcResult_0 = serializefromobject_expr_0_0.getFirst();\\n                serializefromobject_value_1 = (Integer) serializefromobject_funcResult_0;\\n\\n            }\\n        }\\n        // staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType,\\n        // fromString, assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false)\\n        if (serializefromobject_exprIsNull_0_0) {\\n            throw new NullPointerException(((String) references[3] /* errMsg */));\\n        }\\n        boolean serializefromobject_isNull_5 = true;\\n        String serializefromobject_value_5 = null;\\n        if (!false) {\\n            serializefromobject_isNull_5 = false;\\n            if (!serializefromobject_isNull_5) {\\n                Object serializefromobject_funcResult_1 = null;\\n                serializefromobject_funcResult_1 = serializefromobject_expr_0_0.getSecond();\\n                serializefromobject_value_5 = (String) serializefromobject_funcResult_1;\\n\\n            }\\n        }\\n        deserializetoobject_mutableStateArray_0[1] = serializefromobject_value_5;\\n\\n        UTF8String serializefromobject_value_4 = null;\\n        if (!false) {\\n            serializefromobject_value_4 = UTF8String.fromString(deserializetoobject_mutableStateArray_0[1]);\\n        }\\n        deserializetoobject_mutableStateArray_2[4].reset();\\n\\n        deserializetoobject_mutableStateArray_2[4].zeroOutNullBytes();\\n\\n        deserializetoobject_mutableStateArray_2[4].write(0, serializefromobject_value_1);\\n\\n        deserializetoobject_mutableStateArray_2[4].write(1, serializefromobject_value_4);\\n        append((deserializetoobject_mutableStateArray_2[4].getRow()));\\n\\n    }\\n\\n    protected void processNext() throws IOException {\\n        // PRODUCE: SerializeFromObject [assertnotnull(input[0, kotlin.Pair, true]).getFirst AS first#25, \\n        //      staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, \\n        //              assertnotnull(input[0, kotlin.Pair, true]).getSecond, true, false) AS second#26]\\n        // PRODUCE: MapElements me.MainKt$inlined$sam$i$org_apache_spark_api_java_function_MapFunction$0@346a2799, \\n        //      obj#24: kotlin.Pair\\n        // PRODUCE: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n        // PRODUCE: LocalTableScan [first#16, second#17]\\n        while (localtablescan_input_0.hasNext()) {\\n            InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();\\n            ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\\n            // CONSUME: DeserializeToObject newInstance(class kotlin.Pair), obj#23: kotlin.Pair\\n            // input[0, string, false]\\n            UTF8String localtablescan_value_0 = localtablescan_row_0.getUTF8String(0);\\n            // input[1, int, false]\\n            int localtablescan_value_1 = localtablescan_row_0.getInt(1);\\n\\n            deserializetoobject_doConsume_0(localtablescan_row_0, localtablescan_value_0, localtablescan_value_1);\\n            if (shouldStop()) return;\\n        }\\n    }\\n\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-java\"\n  }, \"  public static void copyMemory(\\n    Object src, long srcOffset, Object dst, long dstOffset, long length) {\\n    // Check if dstOffset is before or after srcOffset to determine if we should copy\\n    // forward or backwards. This is necessary in case src and dst overlap.\\n    if (dstOffset < srcOffset) {\\n      while (length > 0) {\\n        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);\\n        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);\\n        length -= size;\\n        srcOffset += size;\\n        dstOffset += size;\\n      }\\n    } else {\\n      srcOffset += length;\\n      dstOffset += length;\\n      while (length > 0) {\\n        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);\\n        srcOffset -= size;\\n        dstOffset -= size;\\n        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);\\n        length -= size;\\n      }\\n\\n    }\\n  }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"8\": true,\n    \"className\": \"language-java\",\n    \"metastring\": \"8 title=\\\"sun.misc.Unsafe O_o\\\"\",\n    \"title\": \"\\\"sun.misc.Unsafe\",\n    \"O_o\\\"\": true\n  }, \"  public static void copyMemory(\\n    Object src, long srcOffset, Object dst, long dstOffset, long length) {\\n    // Check if dstOffset is before or after srcOffset to determine if we should copy\\n    // forward or backwards. This is necessary in case src and dst overlap.\\n    if (dstOffset < srcOffset) {\\n      while (length > 0) {\\n        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);\\n        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);\\n        length -= size;\\n        srcOffset += size;\\n        dstOffset += size;\\n      }\\n    } else {\\n      srcOffset += length;\\n      dstOffset += length;\\n      while (length > 0) {\\n        long size = Math.min(length, UNSAFE_COPY_THRESHOLD);\\n        srcOffset -= size;\\n        dstOffset -= size;\\n        _UNSAFE.copyMemory(src, srcOffset, dst, dstOffset, size);\\n        length -= size;\\n      }\\n\\n    }\\n  }\\n\"))), mdx(\"hr\", null), mdx(\"h1\", null, \"\\u041F\\u043E\\u0447\\u0435\\u043C\\u0443 \\u043C\\u044B \\u0437\\u0430\\u043A\\u043E\\u043D\\u0447\\u0438\\u043B\\u0438 \\u043D\\u0430 \", mdx(\"inlineCode\", {\n    parentName: \"h1\"\n  }, \"_UNSAFE\"), \"?\"), mdx(\"p\", null, \"\\u041F\\u043E\\u0442\\u043E\\u043C\\u0443 \\u0447\\u0442\\u043E \\u0432\\u043F\\u0435\\u0440\\u0435\\u0434\\u0438 \\u0435\\u0449\\u0451 \\u0441\\u043E\\u0440\\u0442\\u0438\\u0440\\u043E\\u0432\\u043A\\u0430\"), mdx(\"hr\", null), mdx(\"h1\", null, \"\\u041F\\u043E\\u0447\\u0435\\u043C\\u0443 \\u043C\\u044B \\u0437\\u0430\\u043A\\u043E\\u043D\\u0447\\u0438\\u043B\\u0438 \\u043D\\u0430 \", mdx(\"inlineCode\", {\n    parentName: \"h1\"\n  }, \"_UNSAFE\"), \"?\"), mdx(\"p\", null, \"\\u041F\\u043E\\u0442\\u043E\\u043C\\u0443 \\u0447\\u0442\\u043E \\u0432\\u043F\\u0435\\u0440\\u0435\\u0434\\u0438 \\u0435\\u0449\\u0451 \\u0441\\u043E\\u0440\\u0442\\u0438\\u0440\\u043E\\u0432\\u043A\\u0430\"), mdx(\"p\", null, \"\\u041D\\u043E \\u044F \\u0432\\u0430\\u043C \\u0435\\u0451 \\u043D\\u0435 \\u043F\\u043E\\u043A\\u0430\\u0436\\u0443\"), mdx(\"p\", null, \"\\u041F\\u043E\\u0440\\u0430 \\u043F\\u043E\\u043D\\u044F\\u0442\\u044C \\u043A\\u0430\\u043A \\u043C\\u044B \\u043A \\u044D\\u0442\\u0438\\u043C \\u0441\\u0433\\u0435\\u043D\\u0435\\u0440\\u0438\\u0440\\u043E\\u0432\\u0430\\u043D\\u043D\\u044B\\u043C \\u0438\\u0441\\u0445\\u043E\\u0434\\u043D\\u0438\\u043A\\u0430\\u043C \\u043F\\u0440\\u0438\\u0445\\u043E\\u0434\\u0438\\u043C\"), mdx(\"hr\", null), mdx(CodeSurfer, {\n    mdxType: \"CodeSurfer\"\n  }, mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n    \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n    .map { it.second - 1 to it.first }\\n    .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n    .debugCodegen()\\n    .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[1:4]\",\n    \"1[1:4]\": true\n  }, \"dsOf(\\\"a\\\" to 1, \\\"b\\\" to 2, \\\"c\\\" to 3, \\\"d\\\" to 4, \\\"e\\\" to 5, \\\"f\\\" to 6,\\n    \\\"g\\\" to 7, \\\"h\\\" to 8, \\\"i\\\" to 9, \\\"j\\\" to 10, \\\"k\\\" to 11, \\\"l\\\" to 12, \\\"m\\\" to 13)\\n    .map { it.second - 1 to it.first }\\n    .sort { arrayOf(it.col(\\\"first\\\").desc()) }\\n    .debugCodegen()\\n    .show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"inline fun <reified T> SparkSession.dsOf(vararg t: T): Dataset<T> =\\n    createDataset(listOf(*t), encoder<T>())\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[31:42]\",\n    \"2[31:42]\": true\n  }, \"inline fun <reified T> SparkSession.dsOf(vararg t: T): Dataset<T> =\\n    createDataset(listOf(*t), encoder<T>())\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\ninline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1,2[64:74] subtitle=\\\" ParametryzedTypeReferense  compile-time\\\"\",\n    \"1,2[64:74]\": true,\n    \"subtitle\": \"\\\"\",\n    \"ParametryzedTypeReferense\": true,\n    \"\": true,\n    \"compile-time\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\ninline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[48:85] subtitle=\\\"encoder  generateEncoder\\\"\",\n    \"2[48:85]\": true,\n    \"subtitle\": \"\\\"encoder\",\n    \"\": true,\n    \"generateEncoder\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\ninline fun <reified T> encoder(): Encoder<T> = generateEncoder(typeOf<T>(), T::class)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"4[53:72]\",\n    \"4[53:72]\": true\n  }, \"fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {\\n    @Suppress(\\\"UNCHECKED_CAST\\\")\\n    return when {\\n        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)\\n        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)\\n    } as Encoder<T>\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"title=\\\"  \\\"\",\n    \"title\": \"\\\"\",\n    \"\": true,\n    \"\\\"\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"title=\\\"  \\\" subtitle=\\\"    ,    \\\"\",\n    \"title\": \"\\\"\",\n    \"\": true,\n    \"\\\"\": true,\n    \"subtitle\": \"\\\"\",\n    \"\": true,\n    \"\": true,\n    \"\": true,\n    \",\": true,\n    \"\": true,\n    \"\": true,\n    \"\\\"\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1:5\",\n    \"1:5\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[16:26] subtitle=\\\"Java PECS  Kotlin PICO\\\"\",\n    \"1[16:26]\": true,\n    \"subtitle\": \"\\\"Java\",\n    \"PECS\": true,\n    \"\": true,\n    \"Kotlin\": true,\n    \"PICO\\\"\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[48:55]\",\n    \"1[48:55]\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[29:43]\",\n    \"1[29:43]\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"2\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2\"\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"3[18:29]\",\n    \"3[18:29]\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"3,4\",\n    \"3,4\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"4[16:36]\",\n    \"4[16:36]\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"1[29:43],3[25:28],4[28:35]\",\n    \"1[29:43],3[25:28],4[28:35]\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"7\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"7\"\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"9\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"9 subtitle=\\\"   (T) -> R\\\"\",\n    \"subtitle\": \"\\\"\",\n    \"\": true,\n    \"\": true,\n    \"(T)\": true,\n    \"->\": true,\n    \"R\\\"\": true\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"9[44:52] subtitle=\\\"schema?\\\"\",\n    \"9[44:52]\": true,\n    \"subtitle\": \"\\\"schema?\\\"\"\n  }, \"class Memoize1<in T, out R>(val f: (T) -> R) : (T) -> R {\\n    private val values = ConcurrentHashMap<T, R>()\\n    override fun invoke(x: T) =\\n        values.getOrPut(x, { f(x) })\\n}\\n\\nprivate fun <T, R> ((T) -> R).memoize(): (T) -> R = Memoize1(this)\\n\\nprivate val memoizedSchema = { x: KType -> schema(x) }.memoize()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"2\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2 file=./schema.kt\",\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[25:57] file=./schema.kt subtitle=\\\"Pair<A, B>  Pair<String, Int>\\\"\",\n    \"2[25:57]\": true,\n    \"file\": \"./schema.kt\",\n    \"subtitle\": \"\\\"Pair<A,\",\n    \"B>\": true,\n    \"\": true,\n    \"Pair<String,\": true,\n    \"Int>\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[61:68] file=./schema.kt subtitle=\\\"Pair<A, B>  Pair<String, Int>\\\"\",\n    \"2[61:68]\": true,\n    \"file\": \"./schema.kt\",\n    \"subtitle\": \"\\\"Pair<A,\",\n    \"B>\": true,\n    \"\": true,\n    \"Pair<String,\": true,\n    \"Int>\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"3:6 file=./schema.kt\",\n    \"3:6\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"private val knownDataTypes = mapOf(\\n    Byte::class to DataTypes.ByteType,\\n    Short::class to DataTypes.ShortType,\\n    Int::class to DataTypes.IntegerType,\\n    Long::class to DataTypes.LongType,\\n    Boolean::class to DataTypes.BooleanType,\\n    Float::class to DataTypes.FloatType,\\n    Double::class to DataTypes.DoubleType,\\n    String::class to DataTypes.StringType,\\n    LocalDate::class to `DateType$`.`MODULE$`,\\n    Date::class to `DateType$`.`MODULE$`,\\n    Timestamp::class to `TimestampType$`.`MODULE$`,\\n    Instant::class to `TimestampType$`.`MODULE$`\\n)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"7\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"7 file=./schema.kt\",\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"9\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"9 file=./schema.kt\",\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"11[38:67] file=./schema.kt subtitle=\\\"List<Pair<KTypeParameter, KTypeProjection>>\\\"\",\n    \"11[38:67]\": true,\n    \"file\": \"./schema.kt\",\n    \"subtitle\": \"\\\"List<Pair<KTypeParameter,\",\n    \"KTypeProjection>>\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"12\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"12 file=./schema.kt subtitle=\\\"\\\\\\\"A\\\\\\\" to String\\\"\",\n    \"file\": \"./schema.kt\",\n    \"subtitle\": \"\\\"\\\\\\\"A\\\\\\\"\",\n    \"to\": true,\n    \"String\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[25:57],11:13 file=./schema.kt subtitle=\\\"Merge types with previous iteration\\\"\",\n    \"2[25:57],11:13\": true,\n    \"file\": \"./schema.kt\",\n    \"subtitle\": \"\\\"Merge\",\n    \"types\": true,\n    \"with\": true,\n    \"previous\": true,\n    \"iteration\\\"\": true\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"15:17 file=./schema.kt\",\n    \"15:17\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"18:36 file=./schema.kt\",\n    \"18:36\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"19[17:25] file=./schema.kt\",\n    \"19[17:25]\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"19[29:53],20:29 file=./schema.kt\",\n    \"19[29:53],20:29\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"30[15:63] file=./schema.kt\",\n    \"30[15:63]\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"31:35 file=./schema.kt\",\n    \"31:35\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"37:49 file=./schema.kt\",\n    \"37:49\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"50:74 file=./schema.kt\",\n    \"50:74\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"52:53 file=./schema.kt\",\n    \"52:53\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"54:55 file=./schema.kt\",\n    \"54:55\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"57\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"57 file=./schema.kt\",\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"58:64 file=./schema.kt\",\n    \"58:64\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"66:69 file=./schema.kt\",\n    \"66:69\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"65:69 file=./schema.kt\",\n    \"65:69\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"73\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"73 file=./schema.kt\",\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"75:94 file=./schema.kt\",\n    \"75:94\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"file=./helpers.scala title=\\\"  \\\"\",\n    \"file\": \"./helpers.scala\",\n    \"title\": \"\\\"\",\n    \"\": true,\n    \"\\\"\": true\n  }, \"trait DataTypeWithClass {\\n  val dt: DataType\\n  val cls: Class[_]\\n  val nullable: Boolean\\n}\\n\\ntrait ComplexWrapper extends DataTypeWithClass\\n\\nclass KDataTypeWrapper(val dt: StructType , val cls: Class[_] , val nullable: Boolean = true)\\n                    extends StructType with ComplexWrapper {\\n    // delegate everything\\n}\\n\\ncase class KComplexTypeWrapper(dt: DataType, cls: Class[_], nullable: Boolean)\\n                    extends DataType with ComplexWrapper {\\n    // delegate everything\\n}\\n\\ncase class KSimpleTypeWrapper(dt: DataType, cls: Class[_], nullable: Boolean)\\n                    extends DataType with DataTypeWithClass {\\n    // delegate everything\\n}\\n\\nclass KStructField(val getterName: String, val delegate: StructField)\\n                    extends StructField {\\n    // delegate everything\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[61:68] file=./schema.kt\",\n    \"2[61:68]\": true,\n    \"file\": \"./schema.kt\"\n  }, \"@OptIn(ExperimentalStdlibApi::class)\\nfun schema(type: KType, map: Map<String, KType> = mapOf()): DataType {\\n    val primitiveSchema = knownDataTypes[type.classifier]\\n    if (primitiveSchema != null) return KSimpleTypeWrapper(primitiveSchema,\\n        (type.classifier!! as KClass<*>).java,\\n        type.isMarkedNullable)\\n    val klass = type.classifier as? KClass<*> ?: \\n        throw IllegalArgumentException(\\\"Unsupported type $type\\\")\\n    val args: List<KTypeProjection> = type.arguments\\n\\n    val types = transitiveMerge(map, klass.typeParameters.zip(args).map {\\n        it.first.name to it.second.type!!\\n    }.toMap())\\n    return when {\\n        klass.isSubclassOf(Enum::class) -> {\\n            KSimpleTypeWrapper(DataTypes.StringType, klass.java, type.isMarkedNullable)\\n        }\\n        klass.isSubclassOf(Iterable::class) || klass.java.isArray -> {\\n            val listParam = if (klass.java.isArray) {\\n                when (klass) {\\n                    IntArray::class -> typeOf<Int>()\\n                    LongArray::class -> typeOf<Long>()\\n                    FloatArray::class -> typeOf<Float>()\\n                    DoubleArray::class -> typeOf<Double>()\\n                    BooleanArray::class -> typeOf<Boolean>()\\n                    ShortArray::class -> typeOf<Short>()\\n                    ByteArray::class -> typeOf<Byte>()\\n                    else -> types.getValue(klass.typeParameters[0].name)\\n                }\\n            } else types.getValue(klass.typeParameters[0].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createArrayType(schema(listParam, types), listParam.isMarkedNullable),\\n                klass.java,\\n                listParam.isMarkedNullable\\n            )\\n        }\\n        klass.isSubclassOf(Map::class) -> {\\n            val mapKeyParam = types.getValue(klass.typeParameters[0].name)\\n            val mapValueParam = types.getValue(klass.typeParameters[1].name)\\n            KComplexTypeWrapper(\\n                DataTypes.createMapType(\\n                    schema(mapKeyParam, types),\\n                    schema(mapValueParam, types),\\n                    true\\n                ),\\n                klass.java,\\n                mapValueParam.isMarkedNullable\\n            )\\n        }\\n        klass.isData -> {\\n            val structType = StructType(\\n                klass\\n                    .primaryConstructor!!\\n                    .parameters\\n                    .filter { it.findAnnotation<Transient>() == null }\\n                    .map {\\n                        val projectedType = types[it.type.toString()] ?: it.type\\n                        val propertyDescriptor = PropertyDescriptor(it.name,\\n                            klass.java,\\n                            \\\"is\\\" + it.name?.replaceFirstChar {\\n                                 if (it.isLowerCase()) it.titlecase(Locale.getDefault()) \\n                                 else it.toString() \\n                            },\\n                            null)\\n                        KStructField(propertyDescriptor.readMethod.name,\\n                            StructField(it.name,\\n                                schema(projectedType, types),\\n                                projectedType.isMarkedNullable,\\n                                Metadata.empty()))\\n                    }\\n                    .toTypedArray()\\n            )\\n            KDataTypeWrapper(structType, klass.java, true)\\n        }\\n        klass.isSubclassOf(Product::class) -> {\\n            val params = type.arguments.mapIndexed { i, it ->\\n                \\\"_${i + 1}\\\" to it.type!!\\n            }\\n\\n            val structType = DataTypes.createStructType(\\n                params.map { (fieldName, fieldType) ->\\n                    val dataType = schema(fieldType, types)\\n                    KStructField(fieldName,\\n                        StructField(\\n                            fieldName, \\n                            dataType, \\n                            fieldType.isMarkedNullable, Metadata.empty()\\n                        )\\n                    )\\n                }.toTypedArray()\\n            )\\n\\n            KComplexTypeWrapper(structType, klass.java, true)\\n        }\\n        else -> throw IllegalArgumentException(\\\"$type is unsupported\\\")\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {\\n    @Suppress(\\\"UNCHECKED_CAST\\\")\\n    return when {\\n        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)\\n        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)\\n    } as Encoder<T>\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"4[34:78]\",\n    \"4[34:78]\": true\n  }, \"fun <T> generateEncoder(type: KType, cls: KClass<*>): Encoder<T> {\\n    @Suppress(\\\"UNCHECKED_CAST\\\")\\n    return when {\\n        isSupportedClass(cls) -> kotlinClassEncoder(memoizedSchema(type), cls)\\n        else -> ENCODERS[cls] as? Encoder<T>? ?: bean(cls.java)\\n    } as Encoder<T>\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\"\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"2\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2\"\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"3,4\",\n    \"3,4\": true\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"5,6\",\n    \"5,6\": true\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"7:10\",\n    \"7:10\": true\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"11\": true,\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"11\"\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-kotlin\",\n    \"metastring\": \"2[12:28]\",\n    \"2[12:28]\": true\n  }, \"private fun <T> kotlinClassEncoder(schema: DataType, kClass: KClass<*>): Encoder<T> {\\n    return ExpressionEncoder(\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.serializerFor(kClass.java, schema)\\n        else\\n            KotlinReflection.serializerForType(KotlinReflection.getType(kClass.java)),\\n        if (schema is DataTypeWithClass) \\n            KotlinReflection.deserializerFor(kClass.java, schema) \\n        else \\n            KotlinReflection.deserializerForType(KotlinReflection.getType(kClass.java)),\\n        ClassTag.apply(kClass.java)\\n    )\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"file=./serializerFor.scala\",\n    \"file\": \"./serializerFor.scala\"\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"1\": true,\n    \"className\": \"language-scala\",\n    \"metastring\": \"1 file=./serializerFor.scala\",\n    \"file\": \"./serializerFor.scala\"\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"1[68:77] file=./serializerFor.scala subtitle=\\\"It's called expression, but really it may be the giant code block\\\"\",\n    \"1[68:77]\": true,\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"It's\",\n    \"called\": true,\n    \"expression,\": true,\n    \"but\": true,\n    \"really\": true,\n    \"it\": true,\n    \"may\": true,\n    \"be\": true,\n    \"the\": true,\n    \"giant\": true,\n    \"code\": true,\n    \"block\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"title=\\\"The most important method\\\"\",\n    \"title\": \"\\\"The\",\n    \"most\": true,\n    \"important\": true,\n    \"method\\\"\": true\n  }, \"  /**\\n   * Returns an [[ExprCode]], that contains the Java source code to generate the result of\\n   * evaluating the expression on an input row.\\n   *\\n   * @param ctx a [[CodegenContext]]\\n   * @return [[ExprCode]]\\n   */\\n  def genCode(ctx: CodegenContext): ExprCode = {\\n      // ommited\\n  }\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"2\": true,\n    \"className\": \"language-scala\",\n    \"metastring\": \"2 file=./serializerFor.scala subtitle=\\\"Obtain Scala type from Java class\\\"\",\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"Obtain\",\n    \"Scala\": true,\n    \"type\": true,\n    \"from\": true,\n    \"Java\": true,\n    \"class\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"3\": true,\n    \"className\": \"language-scala true\",\n    \"metastring\": \"3 file=./serializerFor.scala subtitle=\\\"Obtain class name\\\"\",\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"Obtain\",\n    \"name\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"4\": true,\n    \"className\": \"language-scala\",\n    \"metastring\": \"4 file=./serializerFor.scala subtitle=\\\"Walked typed path is used for exceptions to determine what's going wrong\\\"\",\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"Walked\",\n    \"typed\": true,\n    \"path\": true,\n    \"is\": true,\n    \"used\": true,\n    \"for\": true,\n    \"exceptions\": true,\n    \"to\": true,\n    \"determine\": true,\n    \"what's\": true,\n    \"going\": true,\n    \"wrong\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"6\": true,\n    \"className\": \"language-scala\",\n    \"metastring\": \"6 file=./serializerFor.scala subtitle=\\\"Calling recursive serializer creation\\\"\",\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"Calling\",\n    \"recursive\": true,\n    \"serializer\": true,\n    \"creation\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"6[53:75] file=./serializerFor.scala subtitle=\\\"Supplying our predefined schema\\\"\",\n    \"6[53:75]\": true,\n    \"file\": \"./serializerFor.scala\",\n    \"subtitle\": \"\\\"Supplying\",\n    \"our\": true,\n    \"predefined\": true,\n    \"schema\\\"\": true\n  }, \"def serializerFor(cls: java.lang.Class[_], dt: DataTypeWithClass): Expression = {\\n    val tpe = getType(cls)\\n    val clsName = getClassNameFromType(tpe)\\n    val walkedTypePath = WalkedTypePath().recordRoot(clsName)\\n    val inputObject = BoundReference(0, ObjectType(cls), nullable = true)\\n    serializerFor(inputObject, tpe, walkedTypePath, predefinedDt = Some(dt))\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"file=./serializerFor2.scala subtitle=\\\"316-line-height\\\"\",\n    \"file\": \"./serializerFor2.scala\",\n    \"subtitle\": \"\\\"316-line-height\\\"\"\n  }, \"private def serializerFor(\\n                            inputObject: Expression,\\n                            tpe: `Type`,\\n                            walkedTypePath: WalkedTypePath,\\n                            seenTypeSet: Set[`Type`] = Set.empty,\\n                            predefinedDt: Option[DataTypeWithClass] = None\\n                            ): Expression = cleanUpReflectionObjects {\\n\\n    def toCatalystArray(\\n        input: Expression, \\n        elementType: `Type`, \\n        predefinedDt: Option[DataTypeWithClass] = None): Expression = {\\n        predefinedDt.map(_.dt).getOrElse(dataTypeFor(elementType)) match {\\n        case dt: StructType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(predefinedDt.get.cls),\\n            serializerFor(_, elementType, newPath, seenTypeSet, predefinedDt))\\n\\n        case dt: ObjectType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, dt,\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n        case dt@(BooleanType | ByteType | ShortType | IntegerType | LongType |\\n                    FloatType | DoubleType) =>\\n            val cls = input.dataType.asInstanceOf[ObjectType].cls\\n            if (cls.isArray && cls.getComponentType.isPrimitive) {\\n            createSerializerForPrimitiveArray(input, dt)\\n            } else {\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n            }\\n\\n        case _: StringType =>\\n            val clsName = getClassNameFromType(typeOf[String])\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(Class.forName(getClassNameFromType(elementType))),\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n\\n        case dt =>\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n        }\\n    }\\n\\n    baseType(tpe) match {\\n\\n        //<editor-fold desc=\\\"scala-like\\\">\\n        case _ if !inputObject.dataType.isInstanceOf[ObjectType] && \\n            !predefinedDt.exists(_.isInstanceOf[ComplexWrapper]) => inputObject\\n\\n        case t if isSubtype(t, localTypeOf[Option[_]]) =>\\n            val TypeRef(_, _, Seq(optType)) = t\\n            val className = getClassNameFromType(optType)\\n            val newPath = walkedTypePath.recordOption(className)\\n            val unwrapped = UnwrapOption(dataTypeFor(optType), inputObject)\\n            serializerFor(unwrapped, optType, newPath, seenTypeSet)\\n\\n        // Since List[_] also belongs to localTypeOf[Product], we put this case before\\n        // \\\"case t if definedByConstructorParams(t)\\\" to make sure it will match to the\\n        // case \\\"localTypeOf[Seq[_]]\\\"\\n        case t if isSubtype(t, localTypeOf[Seq[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Array[_]]) && predefinedDt.isEmpty =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Map[_, _]]) =>\\n            val TypeRef(_, _, Seq(keyType, valueType)) = t\\n            val keyClsName = getClassNameFromType(keyType)\\n            val valueClsName = getClassNameFromType(valueType)\\n            val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n            val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n            createSerializerForMap(\\n                inputObject,\\n                MapElementInformation(\\n                dataTypeFor(keyType),\\n                nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, keyType, keyPath, seenTypeSet)),\\n                MapElementInformation(\\n                dataTypeFor(valueType),\\n                nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, valueType, valuePath, seenTypeSet))\\n            )\\n\\n        case t if isSubtype(t, localTypeOf[scala.collection.Set[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n\\n            // There's no corresponding Catalyst type for `Set`, we serialize a `Set` to Catalyst array.\\n            // Note that the property of `Set` is only kept when manipulating the data as domain object.\\n            val newInput =\\n            Invoke(\\n                inputObject,\\n                \\\"toSeq\\\",\\n                ObjectType(classOf[Seq[_]]))\\n\\n            toCatalystArray(newInput, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[String]) =>\\n            createSerializerForString(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.time.Instant]) =>\\n            createSerializerForJavaInstant(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Timestamp]) =>\\n            createSerializerForSqlTimestamp(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.time.LocalDate]) =>\\n            createSerializerForJavaLocalDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Date]) => createSerializerForSqlDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[BigDecimal]) =>\\n            createSerializerForScalaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigDecimal]) =>\\n            createSerializerForJavaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigInteger]) =>\\n            createSerializerForJavaBigInteger(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[scala.math.BigInt]) =>\\n            createSerializerForScalaBigInt(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Integer]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[Int]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Boolean]) => createSerializerForBoolean(inputObject)\\n        case t if isSubtype(t, localTypeOf[Boolean]) => createSerializerForBoolean(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Enum[_]]) =>\\n            createSerializerForString(\\n                Invoke(inputObject, \\\"name\\\", ObjectType(classOf[String]), returnNullable = false))\\n\\n        case t if t.typeSymbol.annotations.exists(_.tree.tpe =:= typeOf[SQLUserDefinedType]) =>\\n            val udt = getClassFromType(t)\\n                .getAnnotation(classOf[SQLUserDefinedType]).udt().getConstructor().newInstance()\\n            val udtClass = udt.userClass.getAnnotation(classOf[SQLUserDefinedType]).udt()\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n\\n        case t if UDTRegistration.exists(getClassNameFromType(t)) =>\\n            val udt = UDTRegistration.getUDTFor(getClassNameFromType(t)).get.getConstructor().\\n                newInstance().asInstanceOf[UserDefinedType[_]]\\n            val udtClass = udt.getClass\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n        //</editor-fold>\\n\\n        case _ if predefinedDt.isDefined =>\\n            predefinedDt.get match {\\n                case dataType: KDataTypeWrapper =>\\n                val cls = dataType.cls\\n                val properties = getJavaBeanReadableProperties(cls)\\n                val structFields = dataType.dt.fields.map(_.asInstanceOf[KStructField])\\n                val fields = structFields.map { structField =>\\n                    val maybeProp = properties.find(it => it.getReadMethod.getName == structField.getterName)\\n                    if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"Field ${structField.name} is not\\n                    found among available props, which are: ${properties.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                    val fieldName = structField.name\\n                    val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                    val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                    val fieldValue = Invoke(\\n                    inputObject,\\n                    maybeProp.get.getReadMethod.getName,\\n                    inferExternalType(propClass),\\n                    returnNullable = propDt.nullable\\n                    )\\n                    val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                    (fieldName, \\n                    serializerFor(\\n                        fieldValue, \\n                        getType(propClass), \\n                        newPath, \\n                        seenTypeSet, if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None)\\n                    )\\n\\n                }\\n                createSerializerForObject(inputObject, fields)\\n\\n                case otherTypeWrapper: ComplexWrapper =>\\n                otherTypeWrapper.dt match {\\n                    case MapType(kt, vt, _) =>\\n                    val Seq(keyType, valueType) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass].cls).map(getType(_))\\n                    val Seq(keyDT, valueDT) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass])\\n                    val keyClsName = getClassNameFromType(keyType)\\n                    val valueClsName = getClassNameFromType(valueType)\\n                    val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n                    val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n                    createSerializerForMap(\\n                        inputObject,\\n                        MapElementInformation(\\n                        dataTypeFor(keyType),\\n                        nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            keyType, \\n                            keyPath, \\n                            seenTypeSet, \\n                            Some(keyDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        )),\\n                        MapElementInformation(\\n                        dataTypeFor(valueType),\\n                        nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            valueType, \\n                            valuePath, \\n                            seenTypeSet, \\n                            Some(valueDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        ))\\n                    )\\n                    case ArrayType(elementType, _) =>\\n                    toCatalystArray(\\n                        inputObject, \\n                        getType(elementType.asInstanceOf[DataTypeWithClass].cls),\\n                        Some(elementType.asInstanceOf[DataTypeWithClass])\\n                    )\\n\\n                    case StructType(elementType: Array[StructField]) =>\\n                    val cls = otherTypeWrapper.cls\\n                    val names = elementType.map(_.name)\\n\\n                    val beanInfo = Introspector.getBeanInfo(cls)\\n                    val methods = beanInfo.getMethodDescriptors.filter(it => names.contains(it.getName))\\n\\n\\n                    val fields = elementType.map { structField =>\\n\\n                        val maybeProp = methods.find(it => it.getName == structField.name)\\n                        if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"\\n                        Field ${structField.name} is not found among available props, \\n                        which are: ${methods.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                        val fieldName = structField.name\\n                        val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                        val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                        val fieldValue = Invoke(\\n                        inputObject,\\n                        maybeProp.get.getName,\\n                        inferExternalType(propClass),\\n                        returnNullable = propDt.nullable\\n                        )\\n                        val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                        (\\n                            fieldName, \\n                            serializerFor(\\n                                fieldValue, \\n                                getType(propClass), \\n                                newPath, \\n                                seenTypeSet, \\n                                if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None\\n                            )\\n                        )\\n\\n                    }\\n                    createSerializerForObject(inputObject, fields)\\n\\n                case _ =>\\n                    throw new UnsupportedOperationException(\\n                        s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n\\n            }\\n        }\\n\\n        case t if definedByConstructorParams(t) =>\\n            if (seenTypeSet.contains(t)) {\\n                throw new UnsupportedOperationException(\\n                s\\\"cannot have circular references in class, but got the circular reference of class $t\\\")\\n            }\\n\\n            val params = getConstructorParameters(t)\\n            val fields = params.map { case (fieldName, fieldType) =>\\n                if (javaKeywords.contains(fieldName)) {\\n                throw new UnsupportedOperationException(s\\\"`$fieldName` is a reserved keyword and \\\" +\\n                    \\\"cannot be used as field name\\\\n\\\" + walkedTypePath)\\n                }\\n\\n                // SPARK-26730 inputObject won't be null with If's guard below. And KnownNotNul\\n                // is necessary here. Because for a nullable nested inputObject with struct data\\n                // type, e.g. StructType(IntegerType, StringType), it will return nullable=true\\n                // for IntegerType without KnownNotNull. And that's what we do not expect to.\\n                val fieldValue = Invoke(KnownNotNull(inputObject), fieldName, dataTypeFor(fieldType),\\n                returnNullable = !fieldType.typeSymbol.asClass.isPrimitive)\\n                val clsName = getClassNameFromType(fieldType)\\n                val newPath = walkedTypePath.recordField(clsName, fieldName)\\n                (fieldName, serializerFor(fieldValue, fieldType, newPath, seenTypeSet + t))\\n            }\\n            createSerializerForObject(inputObject, fields)\\n\\n        case _ =>\\n            throw new UnsupportedOperationException(\\n                s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"1:7 file=./serializerFor2.scala\",\n    \"1:7\": true,\n    \"file\": \"./serializerFor2.scala\"\n  }, \"private def serializerFor(\\n                            inputObject: Expression,\\n                            tpe: `Type`,\\n                            walkedTypePath: WalkedTypePath,\\n                            seenTypeSet: Set[`Type`] = Set.empty,\\n                            predefinedDt: Option[DataTypeWithClass] = None\\n                            ): Expression = cleanUpReflectionObjects {\\n\\n    def toCatalystArray(\\n        input: Expression, \\n        elementType: `Type`, \\n        predefinedDt: Option[DataTypeWithClass] = None): Expression = {\\n        predefinedDt.map(_.dt).getOrElse(dataTypeFor(elementType)) match {\\n        case dt: StructType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(predefinedDt.get.cls),\\n            serializerFor(_, elementType, newPath, seenTypeSet, predefinedDt))\\n\\n        case dt: ObjectType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, dt,\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n        case dt@(BooleanType | ByteType | ShortType | IntegerType | LongType |\\n                    FloatType | DoubleType) =>\\n            val cls = input.dataType.asInstanceOf[ObjectType].cls\\n            if (cls.isArray && cls.getComponentType.isPrimitive) {\\n            createSerializerForPrimitiveArray(input, dt)\\n            } else {\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n            }\\n\\n        case _: StringType =>\\n            val clsName = getClassNameFromType(typeOf[String])\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(Class.forName(getClassNameFromType(elementType))),\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n\\n        case dt =>\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n        }\\n    }\\n\\n    baseType(tpe) match {\\n\\n        //<editor-fold desc=\\\"scala-like\\\">\\n        case _ if !inputObject.dataType.isInstanceOf[ObjectType] && \\n            !predefinedDt.exists(_.isInstanceOf[ComplexWrapper]) => inputObject\\n\\n        case t if isSubtype(t, localTypeOf[Option[_]]) =>\\n            val TypeRef(_, _, Seq(optType)) = t\\n            val className = getClassNameFromType(optType)\\n            val newPath = walkedTypePath.recordOption(className)\\n            val unwrapped = UnwrapOption(dataTypeFor(optType), inputObject)\\n            serializerFor(unwrapped, optType, newPath, seenTypeSet)\\n\\n        // Since List[_] also belongs to localTypeOf[Product], we put this case before\\n        // \\\"case t if definedByConstructorParams(t)\\\" to make sure it will match to the\\n        // case \\\"localTypeOf[Seq[_]]\\\"\\n        case t if isSubtype(t, localTypeOf[Seq[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Array[_]]) && predefinedDt.isEmpty =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Map[_, _]]) =>\\n            val TypeRef(_, _, Seq(keyType, valueType)) = t\\n            val keyClsName = getClassNameFromType(keyType)\\n            val valueClsName = getClassNameFromType(valueType)\\n            val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n            val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n            createSerializerForMap(\\n                inputObject,\\n                MapElementInformation(\\n                dataTypeFor(keyType),\\n                nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, keyType, keyPath, seenTypeSet)),\\n                MapElementInformation(\\n                dataTypeFor(valueType),\\n                nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, valueType, valuePath, seenTypeSet))\\n            )\\n\\n        case t if isSubtype(t, localTypeOf[scala.collection.Set[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n\\n            // There's no corresponding Catalyst type for `Set`, we serialize a `Set` to Catalyst array.\\n            // Note that the property of `Set` is only kept when manipulating the data as domain object.\\n            val newInput =\\n            Invoke(\\n                inputObject,\\n                \\\"toSeq\\\",\\n                ObjectType(classOf[Seq[_]]))\\n\\n            toCatalystArray(newInput, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[String]) =>\\n            createSerializerForString(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.time.Instant]) =>\\n            createSerializerForJavaInstant(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Timestamp]) =>\\n            createSerializerForSqlTimestamp(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.time.LocalDate]) =>\\n            createSerializerForJavaLocalDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Date]) => createSerializerForSqlDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[BigDecimal]) =>\\n            createSerializerForScalaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigDecimal]) =>\\n            createSerializerForJavaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigInteger]) =>\\n            createSerializerForJavaBigInteger(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[scala.math.BigInt]) =>\\n            createSerializerForScalaBigInt(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Integer]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[Int]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Boolean]) => createSerializerForBoolean(inputObject)\\n        case t if isSubtype(t, localTypeOf[Boolean]) => createSerializerForBoolean(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Enum[_]]) =>\\n            createSerializerForString(\\n                Invoke(inputObject, \\\"name\\\", ObjectType(classOf[String]), returnNullable = false))\\n\\n        case t if t.typeSymbol.annotations.exists(_.tree.tpe =:= typeOf[SQLUserDefinedType]) =>\\n            val udt = getClassFromType(t)\\n                .getAnnotation(classOf[SQLUserDefinedType]).udt().getConstructor().newInstance()\\n            val udtClass = udt.userClass.getAnnotation(classOf[SQLUserDefinedType]).udt()\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n\\n        case t if UDTRegistration.exists(getClassNameFromType(t)) =>\\n            val udt = UDTRegistration.getUDTFor(getClassNameFromType(t)).get.getConstructor().\\n                newInstance().asInstanceOf[UserDefinedType[_]]\\n            val udtClass = udt.getClass\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n        //</editor-fold>\\n\\n        case _ if predefinedDt.isDefined =>\\n            predefinedDt.get match {\\n                case dataType: KDataTypeWrapper =>\\n                val cls = dataType.cls\\n                val properties = getJavaBeanReadableProperties(cls)\\n                val structFields = dataType.dt.fields.map(_.asInstanceOf[KStructField])\\n                val fields = structFields.map { structField =>\\n                    val maybeProp = properties.find(it => it.getReadMethod.getName == structField.getterName)\\n                    if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"Field ${structField.name} is not\\n                    found among available props, which are: ${properties.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                    val fieldName = structField.name\\n                    val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                    val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                    val fieldValue = Invoke(\\n                    inputObject,\\n                    maybeProp.get.getReadMethod.getName,\\n                    inferExternalType(propClass),\\n                    returnNullable = propDt.nullable\\n                    )\\n                    val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                    (fieldName, \\n                    serializerFor(\\n                        fieldValue, \\n                        getType(propClass), \\n                        newPath, \\n                        seenTypeSet, if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None)\\n                    )\\n\\n                }\\n                createSerializerForObject(inputObject, fields)\\n\\n                case otherTypeWrapper: ComplexWrapper =>\\n                otherTypeWrapper.dt match {\\n                    case MapType(kt, vt, _) =>\\n                    val Seq(keyType, valueType) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass].cls).map(getType(_))\\n                    val Seq(keyDT, valueDT) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass])\\n                    val keyClsName = getClassNameFromType(keyType)\\n                    val valueClsName = getClassNameFromType(valueType)\\n                    val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n                    val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n                    createSerializerForMap(\\n                        inputObject,\\n                        MapElementInformation(\\n                        dataTypeFor(keyType),\\n                        nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            keyType, \\n                            keyPath, \\n                            seenTypeSet, \\n                            Some(keyDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        )),\\n                        MapElementInformation(\\n                        dataTypeFor(valueType),\\n                        nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            valueType, \\n                            valuePath, \\n                            seenTypeSet, \\n                            Some(valueDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        ))\\n                    )\\n                    case ArrayType(elementType, _) =>\\n                    toCatalystArray(\\n                        inputObject, \\n                        getType(elementType.asInstanceOf[DataTypeWithClass].cls),\\n                        Some(elementType.asInstanceOf[DataTypeWithClass])\\n                    )\\n\\n                    case StructType(elementType: Array[StructField]) =>\\n                    val cls = otherTypeWrapper.cls\\n                    val names = elementType.map(_.name)\\n\\n                    val beanInfo = Introspector.getBeanInfo(cls)\\n                    val methods = beanInfo.getMethodDescriptors.filter(it => names.contains(it.getName))\\n\\n\\n                    val fields = elementType.map { structField =>\\n\\n                        val maybeProp = methods.find(it => it.getName == structField.name)\\n                        if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"\\n                        Field ${structField.name} is not found among available props, \\n                        which are: ${methods.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                        val fieldName = structField.name\\n                        val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                        val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                        val fieldValue = Invoke(\\n                        inputObject,\\n                        maybeProp.get.getName,\\n                        inferExternalType(propClass),\\n                        returnNullable = propDt.nullable\\n                        )\\n                        val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                        (\\n                            fieldName, \\n                            serializerFor(\\n                                fieldValue, \\n                                getType(propClass), \\n                                newPath, \\n                                seenTypeSet, \\n                                if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None\\n                            )\\n                        )\\n\\n                    }\\n                    createSerializerForObject(inputObject, fields)\\n\\n                case _ =>\\n                    throw new UnsupportedOperationException(\\n                        s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n\\n            }\\n        }\\n\\n        case t if definedByConstructorParams(t) =>\\n            if (seenTypeSet.contains(t)) {\\n                throw new UnsupportedOperationException(\\n                s\\\"cannot have circular references in class, but got the circular reference of class $t\\\")\\n            }\\n\\n            val params = getConstructorParameters(t)\\n            val fields = params.map { case (fieldName, fieldType) =>\\n                if (javaKeywords.contains(fieldName)) {\\n                throw new UnsupportedOperationException(s\\\"`$fieldName` is a reserved keyword and \\\" +\\n                    \\\"cannot be used as field name\\\\n\\\" + walkedTypePath)\\n                }\\n\\n                // SPARK-26730 inputObject won't be null with If's guard below. And KnownNotNul\\n                // is necessary here. Because for a nullable nested inputObject with struct data\\n                // type, e.g. StructType(IntegerType, StringType), it will return nullable=true\\n                // for IntegerType without KnownNotNull. And that's what we do not expect to.\\n                val fieldValue = Invoke(KnownNotNull(inputObject), fieldName, dataTypeFor(fieldType),\\n                returnNullable = !fieldType.typeSymbol.asClass.isPrimitive)\\n                val clsName = getClassNameFromType(fieldType)\\n                val newPath = walkedTypePath.recordField(clsName, fieldName)\\n                (fieldName, serializerFor(fieldValue, fieldType, newPath, seenTypeSet + t))\\n            }\\n            createSerializerForObject(inputObject, fields)\\n\\n        case _ =>\\n            throw new UnsupportedOperationException(\\n                s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"58:59 file=./serializerFor2.scala subtitle=\\\"simple input object\\\"\",\n    \"58:59\": true,\n    \"file\": \"./serializerFor2.scala\",\n    \"subtitle\": \"\\\"simple\",\n    \"input\": true,\n    \"object\\\"\": true\n  }, \"private def serializerFor(\\n                            inputObject: Expression,\\n                            tpe: `Type`,\\n                            walkedTypePath: WalkedTypePath,\\n                            seenTypeSet: Set[`Type`] = Set.empty,\\n                            predefinedDt: Option[DataTypeWithClass] = None\\n                            ): Expression = cleanUpReflectionObjects {\\n\\n    def toCatalystArray(\\n        input: Expression, \\n        elementType: `Type`, \\n        predefinedDt: Option[DataTypeWithClass] = None): Expression = {\\n        predefinedDt.map(_.dt).getOrElse(dataTypeFor(elementType)) match {\\n        case dt: StructType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(predefinedDt.get.cls),\\n            serializerFor(_, elementType, newPath, seenTypeSet, predefinedDt))\\n\\n        case dt: ObjectType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, dt,\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n        case dt@(BooleanType | ByteType | ShortType | IntegerType | LongType |\\n                    FloatType | DoubleType) =>\\n            val cls = input.dataType.asInstanceOf[ObjectType].cls\\n            if (cls.isArray && cls.getComponentType.isPrimitive) {\\n            createSerializerForPrimitiveArray(input, dt)\\n            } else {\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n            }\\n\\n        case _: StringType =>\\n            val clsName = getClassNameFromType(typeOf[String])\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(Class.forName(getClassNameFromType(elementType))),\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n\\n        case dt =>\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n        }\\n    }\\n\\n    baseType(tpe) match {\\n\\n        //<editor-fold desc=\\\"scala-like\\\">\\n        case _ if !inputObject.dataType.isInstanceOf[ObjectType] && \\n            !predefinedDt.exists(_.isInstanceOf[ComplexWrapper]) => inputObject\\n\\n        case t if isSubtype(t, localTypeOf[Option[_]]) =>\\n            val TypeRef(_, _, Seq(optType)) = t\\n            val className = getClassNameFromType(optType)\\n            val newPath = walkedTypePath.recordOption(className)\\n            val unwrapped = UnwrapOption(dataTypeFor(optType), inputObject)\\n            serializerFor(unwrapped, optType, newPath, seenTypeSet)\\n\\n        // Since List[_] also belongs to localTypeOf[Product], we put this case before\\n        // \\\"case t if definedByConstructorParams(t)\\\" to make sure it will match to the\\n        // case \\\"localTypeOf[Seq[_]]\\\"\\n        case t if isSubtype(t, localTypeOf[Seq[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Array[_]]) && predefinedDt.isEmpty =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Map[_, _]]) =>\\n            val TypeRef(_, _, Seq(keyType, valueType)) = t\\n            val keyClsName = getClassNameFromType(keyType)\\n            val valueClsName = getClassNameFromType(valueType)\\n            val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n            val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n            createSerializerForMap(\\n                inputObject,\\n                MapElementInformation(\\n                dataTypeFor(keyType),\\n                nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, keyType, keyPath, seenTypeSet)),\\n                MapElementInformation(\\n                dataTypeFor(valueType),\\n                nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, valueType, valuePath, seenTypeSet))\\n            )\\n\\n        case t if isSubtype(t, localTypeOf[scala.collection.Set[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n\\n            // There's no corresponding Catalyst type for `Set`, we serialize a `Set` to Catalyst array.\\n            // Note that the property of `Set` is only kept when manipulating the data as domain object.\\n            val newInput =\\n            Invoke(\\n                inputObject,\\n                \\\"toSeq\\\",\\n                ObjectType(classOf[Seq[_]]))\\n\\n            toCatalystArray(newInput, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[String]) =>\\n            createSerializerForString(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.time.Instant]) =>\\n            createSerializerForJavaInstant(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Timestamp]) =>\\n            createSerializerForSqlTimestamp(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.time.LocalDate]) =>\\n            createSerializerForJavaLocalDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Date]) => createSerializerForSqlDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[BigDecimal]) =>\\n            createSerializerForScalaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigDecimal]) =>\\n            createSerializerForJavaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigInteger]) =>\\n            createSerializerForJavaBigInteger(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[scala.math.BigInt]) =>\\n            createSerializerForScalaBigInt(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Integer]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[Int]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Boolean]) => createSerializerForBoolean(inputObject)\\n        case t if isSubtype(t, localTypeOf[Boolean]) => createSerializerForBoolean(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Enum[_]]) =>\\n            createSerializerForString(\\n                Invoke(inputObject, \\\"name\\\", ObjectType(classOf[String]), returnNullable = false))\\n\\n        case t if t.typeSymbol.annotations.exists(_.tree.tpe =:= typeOf[SQLUserDefinedType]) =>\\n            val udt = getClassFromType(t)\\n                .getAnnotation(classOf[SQLUserDefinedType]).udt().getConstructor().newInstance()\\n            val udtClass = udt.userClass.getAnnotation(classOf[SQLUserDefinedType]).udt()\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n\\n        case t if UDTRegistration.exists(getClassNameFromType(t)) =>\\n            val udt = UDTRegistration.getUDTFor(getClassNameFromType(t)).get.getConstructor().\\n                newInstance().asInstanceOf[UserDefinedType[_]]\\n            val udtClass = udt.getClass\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n        //</editor-fold>\\n\\n        case _ if predefinedDt.isDefined =>\\n            predefinedDt.get match {\\n                case dataType: KDataTypeWrapper =>\\n                val cls = dataType.cls\\n                val properties = getJavaBeanReadableProperties(cls)\\n                val structFields = dataType.dt.fields.map(_.asInstanceOf[KStructField])\\n                val fields = structFields.map { structField =>\\n                    val maybeProp = properties.find(it => it.getReadMethod.getName == structField.getterName)\\n                    if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"Field ${structField.name} is not\\n                    found among available props, which are: ${properties.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                    val fieldName = structField.name\\n                    val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                    val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                    val fieldValue = Invoke(\\n                    inputObject,\\n                    maybeProp.get.getReadMethod.getName,\\n                    inferExternalType(propClass),\\n                    returnNullable = propDt.nullable\\n                    )\\n                    val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                    (fieldName, \\n                    serializerFor(\\n                        fieldValue, \\n                        getType(propClass), \\n                        newPath, \\n                        seenTypeSet, if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None)\\n                    )\\n\\n                }\\n                createSerializerForObject(inputObject, fields)\\n\\n                case otherTypeWrapper: ComplexWrapper =>\\n                otherTypeWrapper.dt match {\\n                    case MapType(kt, vt, _) =>\\n                    val Seq(keyType, valueType) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass].cls).map(getType(_))\\n                    val Seq(keyDT, valueDT) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass])\\n                    val keyClsName = getClassNameFromType(keyType)\\n                    val valueClsName = getClassNameFromType(valueType)\\n                    val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n                    val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n                    createSerializerForMap(\\n                        inputObject,\\n                        MapElementInformation(\\n                        dataTypeFor(keyType),\\n                        nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            keyType, \\n                            keyPath, \\n                            seenTypeSet, \\n                            Some(keyDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        )),\\n                        MapElementInformation(\\n                        dataTypeFor(valueType),\\n                        nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            valueType, \\n                            valuePath, \\n                            seenTypeSet, \\n                            Some(valueDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        ))\\n                    )\\n                    case ArrayType(elementType, _) =>\\n                    toCatalystArray(\\n                        inputObject, \\n                        getType(elementType.asInstanceOf[DataTypeWithClass].cls),\\n                        Some(elementType.asInstanceOf[DataTypeWithClass])\\n                    )\\n\\n                    case StructType(elementType: Array[StructField]) =>\\n                    val cls = otherTypeWrapper.cls\\n                    val names = elementType.map(_.name)\\n\\n                    val beanInfo = Introspector.getBeanInfo(cls)\\n                    val methods = beanInfo.getMethodDescriptors.filter(it => names.contains(it.getName))\\n\\n\\n                    val fields = elementType.map { structField =>\\n\\n                        val maybeProp = methods.find(it => it.getName == structField.name)\\n                        if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"\\n                        Field ${structField.name} is not found among available props, \\n                        which are: ${methods.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                        val fieldName = structField.name\\n                        val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                        val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                        val fieldValue = Invoke(\\n                        inputObject,\\n                        maybeProp.get.getName,\\n                        inferExternalType(propClass),\\n                        returnNullable = propDt.nullable\\n                        )\\n                        val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                        (\\n                            fieldName, \\n                            serializerFor(\\n                                fieldValue, \\n                                getType(propClass), \\n                                newPath, \\n                                seenTypeSet, \\n                                if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None\\n                            )\\n                        )\\n\\n                    }\\n                    createSerializerForObject(inputObject, fields)\\n\\n                case _ =>\\n                    throw new UnsupportedOperationException(\\n                        s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n\\n            }\\n        }\\n\\n        case t if definedByConstructorParams(t) =>\\n            if (seenTypeSet.contains(t)) {\\n                throw new UnsupportedOperationException(\\n                s\\\"cannot have circular references in class, but got the circular reference of class $t\\\")\\n            }\\n\\n            val params = getConstructorParameters(t)\\n            val fields = params.map { case (fieldName, fieldType) =>\\n                if (javaKeywords.contains(fieldName)) {\\n                throw new UnsupportedOperationException(s\\\"`$fieldName` is a reserved keyword and \\\" +\\n                    \\\"cannot be used as field name\\\\n\\\" + walkedTypePath)\\n                }\\n\\n                // SPARK-26730 inputObject won't be null with If's guard below. And KnownNotNul\\n                // is necessary here. Because for a nullable nested inputObject with struct data\\n                // type, e.g. StructType(IntegerType, StringType), it will return nullable=true\\n                // for IntegerType without KnownNotNull. And that's what we do not expect to.\\n                val fieldValue = Invoke(KnownNotNull(inputObject), fieldName, dataTypeFor(fieldType),\\n                returnNullable = !fieldType.typeSymbol.asClass.isPrimitive)\\n                val clsName = getClassNameFromType(fieldType)\\n                val newPath = walkedTypePath.recordField(clsName, fieldName)\\n                (fieldName, serializerFor(fieldValue, fieldType, newPath, seenTypeSet + t))\\n            }\\n            createSerializerForObject(inputObject, fields)\\n\\n        case _ =>\\n            throw new UnsupportedOperationException(\\n                s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"111:112 file=./serializerFor2.scala subtitle=\\\"string\\\"\",\n    \"111:112\": true,\n    \"file\": \"./serializerFor2.scala\",\n    \"subtitle\": \"\\\"string\\\"\"\n  }, \"private def serializerFor(\\n                            inputObject: Expression,\\n                            tpe: `Type`,\\n                            walkedTypePath: WalkedTypePath,\\n                            seenTypeSet: Set[`Type`] = Set.empty,\\n                            predefinedDt: Option[DataTypeWithClass] = None\\n                            ): Expression = cleanUpReflectionObjects {\\n\\n    def toCatalystArray(\\n        input: Expression, \\n        elementType: `Type`, \\n        predefinedDt: Option[DataTypeWithClass] = None): Expression = {\\n        predefinedDt.map(_.dt).getOrElse(dataTypeFor(elementType)) match {\\n        case dt: StructType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(predefinedDt.get.cls),\\n            serializerFor(_, elementType, newPath, seenTypeSet, predefinedDt))\\n\\n        case dt: ObjectType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, dt,\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n        case dt@(BooleanType | ByteType | ShortType | IntegerType | LongType |\\n                    FloatType | DoubleType) =>\\n            val cls = input.dataType.asInstanceOf[ObjectType].cls\\n            if (cls.isArray && cls.getComponentType.isPrimitive) {\\n            createSerializerForPrimitiveArray(input, dt)\\n            } else {\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n            }\\n\\n        case _: StringType =>\\n            val clsName = getClassNameFromType(typeOf[String])\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(Class.forName(getClassNameFromType(elementType))),\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n\\n        case dt =>\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n        }\\n    }\\n\\n    baseType(tpe) match {\\n\\n        //<editor-fold desc=\\\"scala-like\\\">\\n        case _ if !inputObject.dataType.isInstanceOf[ObjectType] && \\n            !predefinedDt.exists(_.isInstanceOf[ComplexWrapper]) => inputObject\\n\\n        case t if isSubtype(t, localTypeOf[Option[_]]) =>\\n            val TypeRef(_, _, Seq(optType)) = t\\n            val className = getClassNameFromType(optType)\\n            val newPath = walkedTypePath.recordOption(className)\\n            val unwrapped = UnwrapOption(dataTypeFor(optType), inputObject)\\n            serializerFor(unwrapped, optType, newPath, seenTypeSet)\\n\\n        // Since List[_] also belongs to localTypeOf[Product], we put this case before\\n        // \\\"case t if definedByConstructorParams(t)\\\" to make sure it will match to the\\n        // case \\\"localTypeOf[Seq[_]]\\\"\\n        case t if isSubtype(t, localTypeOf[Seq[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Array[_]]) && predefinedDt.isEmpty =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Map[_, _]]) =>\\n            val TypeRef(_, _, Seq(keyType, valueType)) = t\\n            val keyClsName = getClassNameFromType(keyType)\\n            val valueClsName = getClassNameFromType(valueType)\\n            val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n            val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n            createSerializerForMap(\\n                inputObject,\\n                MapElementInformation(\\n                dataTypeFor(keyType),\\n                nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, keyType, keyPath, seenTypeSet)),\\n                MapElementInformation(\\n                dataTypeFor(valueType),\\n                nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, valueType, valuePath, seenTypeSet))\\n            )\\n\\n        case t if isSubtype(t, localTypeOf[scala.collection.Set[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n\\n            // There's no corresponding Catalyst type for `Set`, we serialize a `Set` to Catalyst array.\\n            // Note that the property of `Set` is only kept when manipulating the data as domain object.\\n            val newInput =\\n            Invoke(\\n                inputObject,\\n                \\\"toSeq\\\",\\n                ObjectType(classOf[Seq[_]]))\\n\\n            toCatalystArray(newInput, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[String]) =>\\n            createSerializerForString(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.time.Instant]) =>\\n            createSerializerForJavaInstant(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Timestamp]) =>\\n            createSerializerForSqlTimestamp(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.time.LocalDate]) =>\\n            createSerializerForJavaLocalDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Date]) => createSerializerForSqlDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[BigDecimal]) =>\\n            createSerializerForScalaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigDecimal]) =>\\n            createSerializerForJavaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigInteger]) =>\\n            createSerializerForJavaBigInteger(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[scala.math.BigInt]) =>\\n            createSerializerForScalaBigInt(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Integer]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[Int]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Boolean]) => createSerializerForBoolean(inputObject)\\n        case t if isSubtype(t, localTypeOf[Boolean]) => createSerializerForBoolean(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Enum[_]]) =>\\n            createSerializerForString(\\n                Invoke(inputObject, \\\"name\\\", ObjectType(classOf[String]), returnNullable = false))\\n\\n        case t if t.typeSymbol.annotations.exists(_.tree.tpe =:= typeOf[SQLUserDefinedType]) =>\\n            val udt = getClassFromType(t)\\n                .getAnnotation(classOf[SQLUserDefinedType]).udt().getConstructor().newInstance()\\n            val udtClass = udt.userClass.getAnnotation(classOf[SQLUserDefinedType]).udt()\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n\\n        case t if UDTRegistration.exists(getClassNameFromType(t)) =>\\n            val udt = UDTRegistration.getUDTFor(getClassNameFromType(t)).get.getConstructor().\\n                newInstance().asInstanceOf[UserDefinedType[_]]\\n            val udtClass = udt.getClass\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n        //</editor-fold>\\n\\n        case _ if predefinedDt.isDefined =>\\n            predefinedDt.get match {\\n                case dataType: KDataTypeWrapper =>\\n                val cls = dataType.cls\\n                val properties = getJavaBeanReadableProperties(cls)\\n                val structFields = dataType.dt.fields.map(_.asInstanceOf[KStructField])\\n                val fields = structFields.map { structField =>\\n                    val maybeProp = properties.find(it => it.getReadMethod.getName == structField.getterName)\\n                    if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"Field ${structField.name} is not\\n                    found among available props, which are: ${properties.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                    val fieldName = structField.name\\n                    val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                    val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                    val fieldValue = Invoke(\\n                    inputObject,\\n                    maybeProp.get.getReadMethod.getName,\\n                    inferExternalType(propClass),\\n                    returnNullable = propDt.nullable\\n                    )\\n                    val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                    (fieldName, \\n                    serializerFor(\\n                        fieldValue, \\n                        getType(propClass), \\n                        newPath, \\n                        seenTypeSet, if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None)\\n                    )\\n\\n                }\\n                createSerializerForObject(inputObject, fields)\\n\\n                case otherTypeWrapper: ComplexWrapper =>\\n                otherTypeWrapper.dt match {\\n                    case MapType(kt, vt, _) =>\\n                    val Seq(keyType, valueType) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass].cls).map(getType(_))\\n                    val Seq(keyDT, valueDT) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass])\\n                    val keyClsName = getClassNameFromType(keyType)\\n                    val valueClsName = getClassNameFromType(valueType)\\n                    val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n                    val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n                    createSerializerForMap(\\n                        inputObject,\\n                        MapElementInformation(\\n                        dataTypeFor(keyType),\\n                        nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            keyType, \\n                            keyPath, \\n                            seenTypeSet, \\n                            Some(keyDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        )),\\n                        MapElementInformation(\\n                        dataTypeFor(valueType),\\n                        nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            valueType, \\n                            valuePath, \\n                            seenTypeSet, \\n                            Some(valueDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        ))\\n                    )\\n                    case ArrayType(elementType, _) =>\\n                    toCatalystArray(\\n                        inputObject, \\n                        getType(elementType.asInstanceOf[DataTypeWithClass].cls),\\n                        Some(elementType.asInstanceOf[DataTypeWithClass])\\n                    )\\n\\n                    case StructType(elementType: Array[StructField]) =>\\n                    val cls = otherTypeWrapper.cls\\n                    val names = elementType.map(_.name)\\n\\n                    val beanInfo = Introspector.getBeanInfo(cls)\\n                    val methods = beanInfo.getMethodDescriptors.filter(it => names.contains(it.getName))\\n\\n\\n                    val fields = elementType.map { structField =>\\n\\n                        val maybeProp = methods.find(it => it.getName == structField.name)\\n                        if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"\\n                        Field ${structField.name} is not found among available props, \\n                        which are: ${methods.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                        val fieldName = structField.name\\n                        val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                        val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                        val fieldValue = Invoke(\\n                        inputObject,\\n                        maybeProp.get.getName,\\n                        inferExternalType(propClass),\\n                        returnNullable = propDt.nullable\\n                        )\\n                        val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                        (\\n                            fieldName, \\n                            serializerFor(\\n                                fieldValue, \\n                                getType(propClass), \\n                                newPath, \\n                                seenTypeSet, \\n                                if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None\\n                            )\\n                        )\\n\\n                    }\\n                    createSerializerForObject(inputObject, fields)\\n\\n                case _ =>\\n                    throw new UnsupportedOperationException(\\n                        s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n\\n            }\\n        }\\n\\n        case t if definedByConstructorParams(t) =>\\n            if (seenTypeSet.contains(t)) {\\n                throw new UnsupportedOperationException(\\n                s\\\"cannot have circular references in class, but got the circular reference of class $t\\\")\\n            }\\n\\n            val params = getConstructorParameters(t)\\n            val fields = params.map { case (fieldName, fieldType) =>\\n                if (javaKeywords.contains(fieldName)) {\\n                throw new UnsupportedOperationException(s\\\"`$fieldName` is a reserved keyword and \\\" +\\n                    \\\"cannot be used as field name\\\\n\\\" + walkedTypePath)\\n                }\\n\\n                // SPARK-26730 inputObject won't be null with If's guard below. And KnownNotNul\\n                // is necessary here. Because for a nullable nested inputObject with struct data\\n                // type, e.g. StructType(IntegerType, StringType), it will return nullable=true\\n                // for IntegerType without KnownNotNull. And that's what we do not expect to.\\n                val fieldValue = Invoke(KnownNotNull(inputObject), fieldName, dataTypeFor(fieldType),\\n                returnNullable = !fieldType.typeSymbol.asClass.isPrimitive)\\n                val clsName = getClassNameFromType(fieldType)\\n                val newPath = walkedTypePath.recordField(clsName, fieldName)\\n                (fieldName, serializerFor(fieldValue, fieldType, newPath, seenTypeSet + t))\\n            }\\n            createSerializerForObject(inputObject, fields)\\n\\n        case _ =>\\n            throw new UnsupportedOperationException(\\n                s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\"\n  }, \"def createSerializerForString(inputObject: Expression): Expression = {\\n    StaticInvoke(\\n        classOf[UTF8String],\\n        StringType,\\n        \\\"fromString\\\",\\n        inputObject :: Nil,\\n        returnNullable = false)\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-scala\",\n    \"metastring\": \"113:118 file=./serializerFor2.scala subtitle=\\\"string\\\"\",\n    \"113:118\": true,\n    \"file\": \"./serializerFor2.scala\",\n    \"subtitle\": \"\\\"string\\\"\"\n  }, \"private def serializerFor(\\n                            inputObject: Expression,\\n                            tpe: `Type`,\\n                            walkedTypePath: WalkedTypePath,\\n                            seenTypeSet: Set[`Type`] = Set.empty,\\n                            predefinedDt: Option[DataTypeWithClass] = None\\n                            ): Expression = cleanUpReflectionObjects {\\n\\n    def toCatalystArray(\\n        input: Expression, \\n        elementType: `Type`, \\n        predefinedDt: Option[DataTypeWithClass] = None): Expression = {\\n        predefinedDt.map(_.dt).getOrElse(dataTypeFor(elementType)) match {\\n        case dt: StructType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(predefinedDt.get.cls),\\n            serializerFor(_, elementType, newPath, seenTypeSet, predefinedDt))\\n\\n        case dt: ObjectType =>\\n            val clsName = getClassNameFromType(elementType)\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, dt,\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n        case dt@(BooleanType | ByteType | ShortType | IntegerType | LongType |\\n                    FloatType | DoubleType) =>\\n            val cls = input.dataType.asInstanceOf[ObjectType].cls\\n            if (cls.isArray && cls.getComponentType.isPrimitive) {\\n            createSerializerForPrimitiveArray(input, dt)\\n            } else {\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n            }\\n\\n        case _: StringType =>\\n            val clsName = getClassNameFromType(typeOf[String])\\n            val newPath = walkedTypePath.recordArray(clsName)\\n            createSerializerForMapObjects(input, ObjectType(Class.forName(getClassNameFromType(elementType))),\\n            serializerFor(_, elementType, newPath, seenTypeSet))\\n\\n\\n        case dt =>\\n            createSerializerForGenericArray(\\n                input, \\n                dt, \\n                nullable = predefinedDt.map(_.nullable).getOrElse(schemaFor(elementType).nullable)\\n            )\\n        }\\n    }\\n\\n    baseType(tpe) match {\\n\\n        //<editor-fold desc=\\\"scala-like\\\">\\n        case _ if !inputObject.dataType.isInstanceOf[ObjectType] && \\n            !predefinedDt.exists(_.isInstanceOf[ComplexWrapper]) => inputObject\\n\\n        case t if isSubtype(t, localTypeOf[Option[_]]) =>\\n            val TypeRef(_, _, Seq(optType)) = t\\n            val className = getClassNameFromType(optType)\\n            val newPath = walkedTypePath.recordOption(className)\\n            val unwrapped = UnwrapOption(dataTypeFor(optType), inputObject)\\n            serializerFor(unwrapped, optType, newPath, seenTypeSet)\\n\\n        // Since List[_] also belongs to localTypeOf[Product], we put this case before\\n        // \\\"case t if definedByConstructorParams(t)\\\" to make sure it will match to the\\n        // case \\\"localTypeOf[Seq[_]]\\\"\\n        case t if isSubtype(t, localTypeOf[Seq[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Array[_]]) && predefinedDt.isEmpty =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n            toCatalystArray(inputObject, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[Map[_, _]]) =>\\n            val TypeRef(_, _, Seq(keyType, valueType)) = t\\n            val keyClsName = getClassNameFromType(keyType)\\n            val valueClsName = getClassNameFromType(valueType)\\n            val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n            val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n            createSerializerForMap(\\n                inputObject,\\n                MapElementInformation(\\n                dataTypeFor(keyType),\\n                nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, keyType, keyPath, seenTypeSet)),\\n                MapElementInformation(\\n                dataTypeFor(valueType),\\n                nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                serializerFor(_, valueType, valuePath, seenTypeSet))\\n            )\\n\\n        case t if isSubtype(t, localTypeOf[scala.collection.Set[_]]) =>\\n            val TypeRef(_, _, Seq(elementType)) = t\\n\\n            // There's no corresponding Catalyst type for `Set`, we serialize a `Set` to Catalyst array.\\n            // Note that the property of `Set` is only kept when manipulating the data as domain object.\\n            val newInput =\\n            Invoke(\\n                inputObject,\\n                \\\"toSeq\\\",\\n                ObjectType(classOf[Seq[_]]))\\n\\n            toCatalystArray(newInput, elementType)\\n\\n        case t if isSubtype(t, localTypeOf[String]) =>\\n            createSerializerForString(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.time.Instant]) =>\\n            createSerializerForJavaInstant(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Timestamp]) =>\\n            createSerializerForSqlTimestamp(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.time.LocalDate]) =>\\n            createSerializerForJavaLocalDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.sql.Date]) => createSerializerForSqlDate(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[BigDecimal]) =>\\n            createSerializerForScalaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigDecimal]) =>\\n            createSerializerForJavaBigDecimal(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.math.BigInteger]) =>\\n            createSerializerForJavaBigInteger(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[scala.math.BigInt]) =>\\n            createSerializerForScalaBigInt(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Integer]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[Int]) =>\\n            createSerializerForInteger(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[Long]) => createSerializerForLong(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[Double]) => createSerializerForDouble(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[Float]) => createSerializerForFloat(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[Short]) => createSerializerForShort(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[Byte]) => createSerializerForByte(inputObject)\\n        case t if isSubtype(t, localTypeOf[java.lang.Boolean]) => createSerializerForBoolean(inputObject)\\n        case t if isSubtype(t, localTypeOf[Boolean]) => createSerializerForBoolean(inputObject)\\n\\n        case t if isSubtype(t, localTypeOf[java.lang.Enum[_]]) =>\\n            createSerializerForString(\\n                Invoke(inputObject, \\\"name\\\", ObjectType(classOf[String]), returnNullable = false))\\n\\n        case t if t.typeSymbol.annotations.exists(_.tree.tpe =:= typeOf[SQLUserDefinedType]) =>\\n            val udt = getClassFromType(t)\\n                .getAnnotation(classOf[SQLUserDefinedType]).udt().getConstructor().newInstance()\\n            val udtClass = udt.userClass.getAnnotation(classOf[SQLUserDefinedType]).udt()\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n\\n        case t if UDTRegistration.exists(getClassNameFromType(t)) =>\\n            val udt = UDTRegistration.getUDTFor(getClassNameFromType(t)).get.getConstructor().\\n                newInstance().asInstanceOf[UserDefinedType[_]]\\n            val udtClass = udt.getClass\\n            createSerializerForUserDefinedType(inputObject, udt, udtClass)\\n        //</editor-fold>\\n\\n        case _ if predefinedDt.isDefined =>\\n            predefinedDt.get match {\\n                case dataType: KDataTypeWrapper =>\\n                val cls = dataType.cls\\n                val properties = getJavaBeanReadableProperties(cls)\\n                val structFields = dataType.dt.fields.map(_.asInstanceOf[KStructField])\\n                val fields = structFields.map { structField =>\\n                    val maybeProp = properties.find(it => it.getReadMethod.getName == structField.getterName)\\n                    if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"Field ${structField.name} is not\\n                    found among available props, which are: ${properties.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                    val fieldName = structField.name\\n                    val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                    val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                    val fieldValue = Invoke(\\n                    inputObject,\\n                    maybeProp.get.getReadMethod.getName,\\n                    inferExternalType(propClass),\\n                    returnNullable = propDt.nullable\\n                    )\\n                    val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                    (fieldName, \\n                    serializerFor(\\n                        fieldValue, \\n                        getType(propClass), \\n                        newPath, \\n                        seenTypeSet, if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None)\\n                    )\\n\\n                }\\n                createSerializerForObject(inputObject, fields)\\n\\n                case otherTypeWrapper: ComplexWrapper =>\\n                otherTypeWrapper.dt match {\\n                    case MapType(kt, vt, _) =>\\n                    val Seq(keyType, valueType) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass].cls).map(getType(_))\\n                    val Seq(keyDT, valueDT) = Seq(kt, vt).map(_.asInstanceOf[DataTypeWithClass])\\n                    val keyClsName = getClassNameFromType(keyType)\\n                    val valueClsName = getClassNameFromType(valueType)\\n                    val keyPath = walkedTypePath.recordKeyForMap(keyClsName)\\n                    val valuePath = walkedTypePath.recordValueForMap(valueClsName)\\n\\n                    createSerializerForMap(\\n                        inputObject,\\n                        MapElementInformation(\\n                        dataTypeFor(keyType),\\n                        nullable = !keyType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            keyType, \\n                            keyPath, \\n                            seenTypeSet, \\n                            Some(keyDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        )),\\n                        MapElementInformation(\\n                        dataTypeFor(valueType),\\n                        nullable = !valueType.typeSymbol.asClass.isPrimitive,\\n                        serializerFor(\\n                            _, \\n                            valueType, \\n                            valuePath, \\n                            seenTypeSet, \\n                            Some(valueDT).filter(_.isInstanceOf[ComplexWrapper])\\n                        ))\\n                    )\\n                    case ArrayType(elementType, _) =>\\n                    toCatalystArray(\\n                        inputObject, \\n                        getType(elementType.asInstanceOf[DataTypeWithClass].cls),\\n                        Some(elementType.asInstanceOf[DataTypeWithClass])\\n                    )\\n\\n                    case StructType(elementType: Array[StructField]) =>\\n                    val cls = otherTypeWrapper.cls\\n                    val names = elementType.map(_.name)\\n\\n                    val beanInfo = Introspector.getBeanInfo(cls)\\n                    val methods = beanInfo.getMethodDescriptors.filter(it => names.contains(it.getName))\\n\\n\\n                    val fields = elementType.map { structField =>\\n\\n                        val maybeProp = methods.find(it => it.getName == structField.name)\\n                        if (maybeProp.isEmpty) throw new IllegalArgumentException(s\\\"\\\"\\\"\\n                        Field ${structField.name} is not found among available props, \\n                        which are: ${methods.map(_.getName).mkString(\\\", \\\")}\\\"\\\"\\\")\\n                        val fieldName = structField.name\\n                        val propClass = structField.dataType.asInstanceOf[DataTypeWithClass].cls\\n                        val propDt = structField.dataType.asInstanceOf[DataTypeWithClass]\\n                        val fieldValue = Invoke(\\n                        inputObject,\\n                        maybeProp.get.getName,\\n                        inferExternalType(propClass),\\n                        returnNullable = propDt.nullable\\n                        )\\n                        val newPath = walkedTypePath.recordField(propClass.getName, fieldName)\\n                        (\\n                            fieldName, \\n                            serializerFor(\\n                                fieldValue, \\n                                getType(propClass), \\n                                newPath, \\n                                seenTypeSet, \\n                                if (propDt.isInstanceOf[ComplexWrapper]) Some(propDt) else None\\n                            )\\n                        )\\n\\n                    }\\n                    createSerializerForObject(inputObject, fields)\\n\\n                case _ =>\\n                    throw new UnsupportedOperationException(\\n                        s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n\\n            }\\n        }\\n\\n        case t if definedByConstructorParams(t) =>\\n            if (seenTypeSet.contains(t)) {\\n                throw new UnsupportedOperationException(\\n                s\\\"cannot have circular references in class, but got the circular reference of class $t\\\")\\n            }\\n\\n            val params = getConstructorParameters(t)\\n            val fields = params.map { case (fieldName, fieldType) =>\\n                if (javaKeywords.contains(fieldName)) {\\n                throw new UnsupportedOperationException(s\\\"`$fieldName` is a reserved keyword and \\\" +\\n                    \\\"cannot be used as field name\\\\n\\\" + walkedTypePath)\\n                }\\n\\n                // SPARK-26730 inputObject won't be null with If's guard below. And KnownNotNul\\n                // is necessary here. Because for a nullable nested inputObject with struct data\\n                // type, e.g. StructType(IntegerType, StringType), it will return nullable=true\\n                // for IntegerType without KnownNotNull. And that's what we do not expect to.\\n                val fieldValue = Invoke(KnownNotNull(inputObject), fieldName, dataTypeFor(fieldType),\\n                returnNullable = !fieldType.typeSymbol.asClass.isPrimitive)\\n                val clsName = getClassNameFromType(fieldType)\\n                val newPath = walkedTypePath.recordField(clsName, fieldName)\\n                (fieldName, serializerFor(fieldValue, fieldType, newPath, seenTypeSet + t))\\n            }\\n            createSerializerForObject(inputObject, fields)\\n\\n        case _ =>\\n            throw new UnsupportedOperationException(\\n                s\\\"No Encoder found for $tpe\\\\n\\\" + walkedTypePath)\\n    }\\n}\\n\"))), mdx(\"hr\", null), mdx(\"h1\", null, \"The End\"));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"matchPath":"/*","id":"5c475aae-6962-52cb-b39f-edcd89e96b3f","slug":"","title":"Spark Magic:"}},"staticQueryHashes":[]}